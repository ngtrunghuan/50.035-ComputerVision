{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's this TensorFlow business?\n",
    "\n",
    "You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "For the last part of this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, TensorFlow (or PyTorch, if you switch over to that notebook)\n",
    "\n",
    "#### What is it?\n",
    "TensorFlow is a system for executing computational graphs over Tensor objects, with native support for performing backpropogation for its Variables. In it, we work with Tensors which are n-dimensional arrays analogous to the numpy ndarray.\n",
    "\n",
    "#### Why?\n",
    "\n",
    "* Our code will now run on GPUs! Much faster training. Writing your own modules to run on GPUs is beyond the scope of this class, unfortunately.\n",
    "* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants, e.g., TensorFlow. This very excellent framework will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* We want you to be exposed to the sort of deep learning code you might run into in academia or industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgement: This exercise is adapted from [Stanford CS231n](http://cs231n.stanford.edu/index.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How will I learn TensorFlow?\n",
    "\n",
    "TensorFlow has many excellent tutorials available, including those from [Google themselves](https://www.tensorflow.org/get_started/get_started).\n",
    "\n",
    "Otherwise, this notebook will walk you through much of what you need to do to train models in TensorFlow. See the end of the notebook for some links to helpful tutorials if you want to learn more or need further clarification on topics that aren't fully explained here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.tf_layers import *\n",
    "from libs.vis_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from libs.data_utils import load_CIFAR10\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'libs/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model\n",
    "\n",
    "### Some useful utilities\n",
    "\n",
    ". Remember that our image data is initially N x H x W x C, where:\n",
    "* N is the number of datapoints (mini-batch size)\n",
    "* H is the height of each image in pixels\n",
    "* W is the height of each image in pixels\n",
    "* C is the number of channels (usually 3: R, G, B)\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, which needs spatial understanding of where the pixels are relative to each other. When we input image data into fully connected affine layers, however, we want each data example to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example model itself\n",
    "\n",
    "The first step to training your own model is defining its architecture.\n",
    "\n",
    "Here's an example of a convolutional neural network defined in TensorFlow -- try to understand what each line is doing, remembering that each layer is composed upon the previous layer. We haven't trained anything yet - that'll come next - for now, we want you to understand how everything gets set up. \n",
    "\n",
    "In that example, you see 2D convolutional layers (Conv2d), ReLU activations, and fully-connected layers (Linear). You also see the Hinge loss (multi-class SVM) function, and the SGD optimizer being used. \n",
    "\n",
    "Make sure you understand **why the parameters of the Linear layer are 5408 and 10**. You can refer to the material from [CS231n webpages](http://cs231n.github.io/convolutional-networks/).\n",
    "\n",
    "### TensorFlow Details\n",
    "In TensorFlow, much like in our previous notebooks, we'll first specifically initialize our variables, and then our network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(2e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports many other layer types, loss functions, and optimizers - you will experiment with these next. Here's the official API documentation for these (if any of the parameters used above were unclear, this resource will also be helpful). \n",
    "\n",
    "* Layers, Activations, Loss functions : https://www.tensorflow.org/api_guides/python/nn\n",
    "* Optimizers: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "* BatchNorm: https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm. Note that there are few other implementations of batch normalization layers, e.g., [link 1](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm), [link 2](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on one epoch\n",
    "Define the function to train a model as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, correct_prediction, accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_correct,losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have defined a graph of operations above, in order to execute TensorFlow Graphs, by feeding them input data and computing the results, we first need to create a `tf.Session` object. A session encapsulates the control and state of the TensorFlow runtime. For more information, see the TensorFlow [Getting started](https://www.tensorflow.org/get_started/get_started) guide.\n",
    "\n",
    "Optionally we can also specify a device context such as `/cpu:0` or `/gpu:0`. For documentation on this behavior see [this TensorFlow guide](https://www.tensorflow.org/tutorials/using_gpu). Generally, if your machine has GPU available (with all required drivers) and you install Tensorflow GPU version, Tensorflow will automatically select GPU as the primary device. Otherwise, CPU will be selected as the primary device.\n",
    "\n",
    "You should see a validation loss of around 1 and an accuracy of 0.2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iteration 0: with minibatch training loss = 12.6 and accuracy of 0.14\n",
      "Iteration 100: with minibatch training loss = 1.86 and accuracy of 0.11\n",
      "Iteration 200: with minibatch training loss = 1.56 and accuracy of 0.17\n",
      "Iteration 300: with minibatch training loss = 1.38 and accuracy of 0.22\n",
      "Iteration 400: with minibatch training loss = 1.3 and accuracy of 0.19\n",
      "Iteration 500: with minibatch training loss = 1.23 and accuracy of 0.2\n",
      "Iteration 600: with minibatch training loss = 0.926 and accuracy of 0.25\n",
      "Iteration 700: with minibatch training loss = 1.23 and accuracy of 0.17\n",
      "Epoch 1, Overall loss = 1.49 and accuracy of 0.207\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLGkYY4wJ2f8HORdK6Uvjy/sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1767a7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 1.08 and accuracy of 0.224\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,plot_losses=True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.20301172493953412&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_2&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.05914847552776337\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.05914847552776337\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/max&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/mul&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Wconv1&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Wconv1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.3061862289905548\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.3061862289905548\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/max&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/mul&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bconv1&quot;\\n  input: &quot;bconv1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bconv1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\025\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.03327791765332222\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.03327791765332222\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;W1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;W1/Initializer/random_uniform/max&quot;\\n  input: &quot;W1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;W1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;W1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;W1/Initializer/random_uniform/mul&quot;\\n  input: &quot;W1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5408\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;W1&quot;\\n  input: &quot;W1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;W1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;b1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;b1/Initializer/random_uniform/max&quot;\\n  input: &quot;b1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;b1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;b1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;b1/Initializer/random_uniform/mul&quot;\\n  input: &quot;b1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;b1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Wconv1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2D&quot;\\n  input: &quot;bconv1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377 \\\\025\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Relu&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;W1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;b1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;Placeholder_1&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/mul/x&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hinge_loss/mul&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  input: &quot;hinge_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;hinge_loss/Sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;hinge_loss/ToFloat_3/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/Mul_1&quot;\\n  input: &quot;hinge_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  input: &quot;hinge_loss/num_present/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/num_present/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/num_present/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/num_present/Equal&quot;\\n  input: &quot;hinge_loss/num_present/zeros_like&quot;\\n  input: &quot;hinge_loss/num_present/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/num_present/Select&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  input: &quot;hinge_loss/num_present/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/Sum&quot;\\n  input: &quot;hinge_loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Greater/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  input: &quot;hinge_loss/Greater/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  input: &quot;hinge_loss/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/ones_like_1/Shape&quot;\\n  input: &quot;hinge_loss/ones_like_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;hinge_loss/ones_like_1&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;hinge_loss/Sum_1&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/value&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;hinge_loss/div&quot;\\n  input: &quot;hinge_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;hinge_loss/value&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/value_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/Select_1&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/value_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;hinge_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Neg&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv_1&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/num_present/Select&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Neg&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;W1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Wconv1/read&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/Conv2D_grad/ShapeN&quot;\\n  input: &quot;Wconv1/read&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;gradients/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.00019999999494757503\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_Wconv1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;Wconv1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_bconv1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;bconv1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_W1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;W1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_b1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_Wconv1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_bconv1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_W1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_b1/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Wconv1/Assign&quot;\\n  input: &quot;^bconv1/Assign&quot;\\n  input: &quot;^W1/Assign&quot;\\n  input: &quot;^b1/Assign&quot;\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax_1/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax_1&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;ArgMax_1/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal_1&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax_1&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_2&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast_1&quot;\\n  input: &quot;Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.20301172493953412&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard for Visualization\n",
    "\n",
    "Tensorflow provides a very useful tool: Tensorboard. This is very helpful to visualize the training loss, accuray, filters,...\n",
    "\n",
    "Here is a good video about Tensorboard: https://www.youtube.com/watch?v=eBbEDRsCmv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "    variable_summaries(Wconv1)\n",
    "    variable_summaries(W1)\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(2e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_with_tensorboard(session, predict, loss_value, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, tensorboard_writer=None):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    tf.summary.scalar(\"cost\", loss_value)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        batch_count = int(math.ceil(Xd.shape[0]/batch_size))\n",
    "        for i in range(batch_count):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            \n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            if training_now:\n",
    "                _, summary = session.run([training, summary_op],feed_dict=feed_dict)\n",
    "                # write log\n",
    "                tensorboard_writer.add_summary(summary, e * batch_count + i)\n",
    "            else:\n",
    "                summary = session.run(summary_op, feed_dict=feed_dict)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer\n",
      "Training\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=logs/train \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "# define SGD optimizer\n",
    "print('SGD optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter('logs/train', graph=tf.get_default_graph())\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model_with_tensorboard(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,\n",
    "                               tensorboard_writer=train_writer)\n",
    "\n",
    "# tensorboard --logdir=logs/train\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=logs/train \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "# NOTE: In Window, you may not able to run the Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "\n",
    "You are going to see [ADAM optimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) being used. Now, we will compare the training loss curves of a model with SGD and ADAM optimizers.\n",
    "\n",
    "You can try other optimizers, e.g., [SGD+Momentum](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer), [RMSprop](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer), [Adagrad](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer), [Adadelta](https://www.tensorflow.org/api_docs/python/tf/train/AdadeltaOptimizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 9.12 and accuracy of 0.062\n",
      "Iteration 100: with minibatch training loss = 2.19 and accuracy of 0.16\n",
      "Iteration 200: with minibatch training loss = 1.94 and accuracy of 0.22\n",
      "Iteration 300: with minibatch training loss = 1.52 and accuracy of 0.31\n",
      "Iteration 400: with minibatch training loss = 1.5 and accuracy of 0.22\n",
      "Iteration 500: with minibatch training loss = 1.58 and accuracy of 0.2\n",
      "Iteration 600: with minibatch training loss = 1.28 and accuracy of 0.19\n",
      "Iteration 700: with minibatch training loss = 1.42 and accuracy of 0.19\n",
      "Epoch 1, Overall loss = 1.78 and accuracy of 0.187\n",
      "Validation\n",
      "Epoch 1, Overall loss = 1.34 and accuracy of 0.249\n",
      "==========================================================\n",
      "\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 13.7 and accuracy of 0.12\n",
      "Iteration 100: with minibatch training loss = 1.7 and accuracy of 0.23\n",
      "Iteration 200: with minibatch training loss = 1.22 and accuracy of 0.17\n",
      "Iteration 300: with minibatch training loss = 1.07 and accuracy of 0.28\n",
      "Iteration 400: with minibatch training loss = 1.06 and accuracy of 0.22\n",
      "Iteration 500: with minibatch training loss = 0.817 and accuracy of 0.23\n",
      "Iteration 600: with minibatch training loss = 0.813 and accuracy of 0.27\n",
      "Iteration 700: with minibatch training loss = 0.749 and accuracy of 0.27\n",
      "Epoch 1, Overall loss = 1.22 and accuracy of 0.266\n",
      "Validation\n",
      "Epoch 1, Overall loss = 0.712 and accuracy of 0.311\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQmnEQRBEJTm/xdoepiyARvjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17638ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "print('SGD optimizer')\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, sgd_losses = run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "\n",
    "print(\"==========================================================\\n\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses = run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "    \n",
    "plt.plot(sgd_losses, label='SGD')\n",
    "plt.plot(adam_losses, label='ADAM')\n",
    "# plt.plot(adam_losses_batchnorm, label='ADAM+BatchNorm')\n",
    "# plt.ylim( (0, 100) ) \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Epoch 1 Loss')\n",
    "plt.xlabel('minibatch number')\n",
    "plt.ylabel('minibatch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go Deeper\n",
    "\n",
    "In the previous exercises, you are required to implement different functions, e.g., affine, relu, conv2d, ... which serve as basic module to build a Deep Neuron Network. Similarly, we provide the basic modules for Tensorflow in `libs/tf_layers.py`.\n",
    "\n",
    "**NOTE:** In this exercise, you are welcome to change the block functions in `libs/tf_layers.py` to fit your needs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a deep network\n",
    "def deep_model(X, y, batchnorm=False, name=None):\n",
    "    output = Conv2D(X, 3, 7, 8, name=name+'_conv1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu1')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN1')\n",
    "    output = Conv2D(output, 8, 7, 8, name=name+'_conv2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu2')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN2')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool1')\n",
    "    output = Conv2D(output, 8, 7, 16, name=name+'_conv3')\n",
    "    output = tf.nn.relu(output, name=name+'_relu3')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN3')\n",
    "    output = Conv2D(output, 16, 7, 16, name=name+'_conv4')\n",
    "    \n",
    "    # Here is another way of defining a name for a layer\n",
    "    with tf.variable_scope(name+'_relu4'):\n",
    "#         output = tf.nn.relu(output, name=name+'_relu4')\n",
    "        output = tf.nn.relu(output)\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN4')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool2')\n",
    "    output = tf.reshape(output, [-1, 16*8*8], name=name+'_flatten')\n",
    "    output = FullyConnected(output, 16*8*8, 100, name=name+'_fc1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu5')\n",
    "    output = FullyConnected(output, 100, 100, name=name+'_fc2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu6')\n",
    "    output = FullyConnected(output, 100, 10, name=name+'_fc3')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now see the benefit of using **batch normalization** layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 1.07 and accuracy of 0.047\n",
      "Iteration 100: with minibatch training loss = 0.29 and accuracy of 0.19\n",
      "Iteration 200: with minibatch training loss = 0.246 and accuracy of 0.3\n",
      "Iteration 300: with minibatch training loss = 0.239 and accuracy of 0.34\n",
      "Iteration 400: with minibatch training loss = 0.239 and accuracy of 0.27\n",
      "Iteration 500: with minibatch training loss = 0.234 and accuracy of 0.2\n",
      "Iteration 600: with minibatch training loss = 0.227 and accuracy of 0.27\n",
      "Iteration 700: with minibatch training loss = 0.222 and accuracy of 0.36\n",
      "Epoch 1, Overall loss = 0.257 and accuracy of 0.273\n",
      "Validation\n",
      "Epoch 1, Overall loss = 0.218 and accuracy of 0.357\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176825e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out_deep2 = deep_model(X,y, True, name='deep2')\n",
    "# define our loss\n",
    "total_loss_deep2 = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out_deep2)\n",
    "mean_loss = tf.reduce_mean(total_loss_deep2)\n",
    "\n",
    "print(\"==========================================================\\n\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)\n",
    "    \n",
    "plt.plot(sgd_losses, label='SGD')\n",
    "plt.plot(adam_losses, label='ADAM')\n",
    "plt.plot(adam_losses_batchnorm, label='ADAM+BatchNorm')\n",
    "plt.ylim( (0, 100) ) \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Epoch 1 Loss')\n",
    "plt.xlabel('minibatch number')\n",
    "plt.ylabel('minibatch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More epochs\n",
    "Train the model with more epochs to see how good performance it can achieve.\n",
    "\n",
    "**NOTE:** If you run this on a CPU, it will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "ADAM optimizer\n",
      "<tensorflow.python.client.session.Session object at 0x11949b780>\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 1.45 and accuracy of 0.094\n",
      "Iteration 100: with minibatch training loss = 0.301 and accuracy of 0.17\n",
      "Iteration 200: with minibatch training loss = 0.267 and accuracy of 0.27\n",
      "Iteration 300: with minibatch training loss = 0.265 and accuracy of 0.2\n",
      "Iteration 400: with minibatch training loss = 0.254 and accuracy of 0.25\n",
      "Iteration 500: with minibatch training loss = 0.229 and accuracy of 0.27\n",
      "Iteration 600: with minibatch training loss = 0.217 and accuracy of 0.41\n",
      "Iteration 700: with minibatch training loss = 0.223 and accuracy of 0.36\n",
      "Epoch 1, Overall loss = 0.272 and accuracy of 0.274\n",
      "Iteration 800: with minibatch training loss = 0.225 and accuracy of 0.22\n",
      "Iteration 900: with minibatch training loss = 0.216 and accuracy of 0.41\n",
      "Iteration 1000: with minibatch training loss = 0.226 and accuracy of 0.38\n",
      "Iteration 1100: with minibatch training loss = 0.22 and accuracy of 0.36\n",
      "Iteration 1200: with minibatch training loss = 0.218 and accuracy of 0.42\n",
      "Iteration 1300: with minibatch training loss = 0.202 and accuracy of 0.5\n",
      "Iteration 1400: with minibatch training loss = 0.222 and accuracy of 0.33\n",
      "Iteration 1500: with minibatch training loss = 0.198 and accuracy of 0.42\n",
      "Epoch 2, Overall loss = 0.486 and accuracy of 0.395\n",
      "Iteration 1600: with minibatch training loss = 0.21 and accuracy of 0.39\n",
      "Iteration 1700: with minibatch training loss = 0.218 and accuracy of 0.34\n",
      "Iteration 1800: with minibatch training loss = 0.198 and accuracy of 0.5\n",
      "Iteration 1900: with minibatch training loss = 0.203 and accuracy of 0.44\n",
      "Iteration 2000: with minibatch training loss = 0.198 and accuracy of 0.42\n",
      "Iteration 2100: with minibatch training loss = 0.207 and accuracy of 0.42\n",
      "Iteration 2200: with minibatch training loss = 0.201 and accuracy of 0.38\n",
      "Epoch 3, Overall loss = 0.688 and accuracy of 0.453\n",
      "Iteration 2300: with minibatch training loss = 0.195 and accuracy of 0.48\n",
      "Iteration 2400: with minibatch training loss = 0.218 and accuracy of 0.31\n",
      "Iteration 2500: with minibatch training loss = 0.203 and accuracy of 0.47\n",
      "Iteration 2600: with minibatch training loss = 0.206 and accuracy of 0.52\n",
      "Iteration 2700: with minibatch training loss = 0.209 and accuracy of 0.36\n",
      "Iteration 2800: with minibatch training loss = 0.197 and accuracy of 0.56\n",
      "Iteration 2900: with minibatch training loss = 0.168 and accuracy of 0.62\n",
      "Iteration 3000: with minibatch training loss = 0.171 and accuracy of 0.52\n",
      "Epoch 4, Overall loss = 0.878 and accuracy of 0.492\n",
      "Iteration 3100: with minibatch training loss = 0.183 and accuracy of 0.53\n",
      "Iteration 3200: with minibatch training loss = 0.17 and accuracy of 0.58\n",
      "Iteration 3300: with minibatch training loss = 0.163 and accuracy of 0.56\n",
      "Iteration 3400: with minibatch training loss = 0.188 and accuracy of 0.45\n",
      "Iteration 3500: with minibatch training loss = 0.176 and accuracy of 0.55\n",
      "Iteration 3600: with minibatch training loss = 0.179 and accuracy of 0.55\n",
      "Iteration 3700: with minibatch training loss = 0.188 and accuracy of 0.44\n",
      "Iteration 3800: with minibatch training loss = 0.171 and accuracy of 0.58\n",
      "Epoch 5, Overall loss = 1.06 and accuracy of 0.53\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11949b3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 0.176 and accuracy of 0.54\n"
     ]
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out_deep2 = deep_model(X,y, True, name='deep2')\n",
    "# define our loss\n",
    "total_loss_deep2 = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out_deep2)\n",
    "mean_loss = tf.reduce_mean(total_loss_deep2)\n",
    "\n",
    "print(\"==========================================================\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    print(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,5,64,100,train_step,True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a _GREAT_ model on CIFAR-10!\n",
    "\n",
    "### Things you should try:\n",
    "- **Filter size**: Above we used 7x7; bigger filters captures more information but smaller filters may be more computationally efficient.\n",
    "- **Number of filters**: Above we used 32 (or less) filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Use TensorFlow Scope**: Use TensorFlow scope and/or [tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers) to make it easier to write deeper networks. See [this tutorial](https://www.tensorflow.org/tutorials/layers) for how to use `tf.layers`. \n",
    "- **Use Learning Rate Decay**: [As the notes point out](http://cs231n.github.io/neural-networks-3/#anneal), decaying the learning rate might help the model converge. Feel free to decay every epoch, when loss doesn't change over an entire epoch, or any other heuristic you find appropriate. See the [Tensorflow documentation](https://www.tensorflow.org/versions/master/api_guides/python/train#Decaying_the_learning_rate) for learning rate decay.\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use [Dropout as in the TensorFlow MNIST tutorial](https://www.tensorflow.org/get_started/mnist/pros).\n",
    "\n",
    "**NOTE:**\n",
    "* In this exercise, you are welcome to change the block functions in `libs/tf_layers.py` to fit your needs the best.\n",
    "* Softmax cross-entropy loss: [tf.losses.softmax_cross_entropy](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/losses/softmax_cross_entropy)\n",
    "* SVM loss: [tf.losses.hinge_loss](https://www.tensorflow.org/api_docs/python/tf/losses/hinge_loss)\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should **see improvement within a few hundred iterations.**\n",
    "- Remember the **coarse-to-fine** approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should **use the validation set for hyperparameter search**, and we'll save the test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "\n",
    "\n",
    "### What we expect\n",
    "At the very least, you should be able to train a ConvNet that gets at **>= 60% accuracy on the validation set**. This is just a lower bound - if you are careful it should be possible to get accuracies much higher than that! Extra credit points will be awarded for particularly high-scoring models or unique approaches.\n",
    "\n",
    "You should use the space below to experiment and train your network. The final cell in this notebook should contain the training and validation set accuracies for your final trained network.\n",
    "\n",
    "Have fun and happy training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these; however they would be good things to try for extra credit.\n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum, RMSprop, and Adam; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "If you do decide to implement something extra, clearly describe it in the \"Extra Credit Description\" cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play with this cell\n",
    "# You can implement the model in a seperate python file.\n",
    "\n",
    "def my_model(X,y):\n",
    "    name = 'myModel'\n",
    "    output = Conv2D(X, 3, 7, 8, name=name+'_conv1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu1')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN1')\n",
    "    output = Conv2D(output, 8, 7, 8, name=name+'_conv2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu2')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN2')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool1')\n",
    "    output = Conv2D(output, 8, 7, 16, name=name+'_conv3')\n",
    "    output = tf.nn.relu(output, name=name+'_relu3')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN3')\n",
    "    output = Conv2D(output, 16, 7, 16, name=name+'_conv4')\n",
    "    output = tf.nn.relu(output, name=name+'_relu4')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN4')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool2')\n",
    "    output = tf.reshape(output, [-1, 16*8*8], name=name+'_flatten')\n",
    "    output = FullyConnected(output, 16*8*8, 100, name=name+'_fc1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu5')\n",
    "    output = FullyConnected(output, 100, 100, name=name+'_fc2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu6')\n",
    "    output = FullyConnected(output, 100, 10, name=name+'_fc3')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x17b46c518>\n",
      "Training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'Mean:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Mean:0\", shape=(), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    270\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 271\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    272\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3113\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3115\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Mean:0\", shape=(), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ef99cb9b1235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-297e07ab9e6c>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(session, predict, loss_val, Xd, yd, epochs, batch_size, print_every, training, plot_losses)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# have tensorflow compute loss and correct predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# and (if given) perform a training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1105\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \"\"\"\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \"\"\"\n\u001b[1;32m    340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \"\"\"\n\u001b[1;32m    340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 278\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    279\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Mean:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Mean:0\", shape=(), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "# Feel free to play with this cell\n",
    "# This default code creates a session\n",
    "# and trains your model for 10 epochs\n",
    "# then prints the validation set accuracy\n",
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = my_model(X,y)\n",
    "my_total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "my_mean_loss = tf.reduce_mean(my_total_loss)\n",
    "my_optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = my_optimizer.minimize(my_mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_,out = run_model(sess,y_out,mean_loss,X_train,y_train,10,64,100,train_step,True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test your model here, and make sure \n",
    "# the output of this cell is the accuracy\n",
    "# of your best model on the training and val sets\n",
    "# We're looking for >= 60% accuracy on Validation\n",
    "print('Training')\n",
    "run_model(sess,y_out,mean_loss,X_train,y_train,1,64)\n",
    "print('Validation')\n",
    "run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set - DO THIS ONLY ONCE\n",
    "Now that we've gotten a result that we're happy with, we test our final model on the test set. This would be the score we would achieve on a competition. Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test')\n",
    "run_model(sess,y_out,mean_loss,X_test,y_test,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit Description\n",
    "Briefly describe what you did here.\n",
    "\n",
    "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tell us here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
