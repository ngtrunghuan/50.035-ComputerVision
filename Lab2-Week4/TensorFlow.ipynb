{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's this TensorFlow business?\n",
    "\n",
    "You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "For the last part of this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, TensorFlow (or PyTorch, if you switch over to that notebook)\n",
    "\n",
    "#### What is it?\n",
    "TensorFlow is a system for executing computational graphs over Tensor objects, with native support for performing backpropogation for its Variables. In it, we work with Tensors which are n-dimensional arrays analogous to the numpy ndarray.\n",
    "\n",
    "#### Why?\n",
    "\n",
    "* Our code will now run on GPUs! Much faster training. Writing your own modules to run on GPUs is beyond the scope of this class, unfortunately.\n",
    "* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants, e.g., TensorFlow. This very excellent framework will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* We want you to be exposed to the sort of deep learning code you might run into in academia or industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgement: This exercise is adapted from [Stanford CS231n](http://cs231n.stanford.edu/index.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How will I learn TensorFlow?\n",
    "\n",
    "TensorFlow has many excellent tutorials available, including those from [Google themselves](https://www.tensorflow.org/get_started/get_started).\n",
    "\n",
    "Otherwise, this notebook will walk you through much of what you need to do to train models in TensorFlow. See the end of the notebook for some links to helpful tutorials if you want to learn more or need further clarification on topics that aren't fully explained here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.tf_layers import *\n",
    "from libs.vis_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from libs.data_utils import load_CIFAR10\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'libs/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model\n",
    "\n",
    "### Some useful utilities\n",
    "\n",
    ". Remember that our image data is initially N x H x W x C, where:\n",
    "* N is the number of datapoints (mini-batch size)\n",
    "* H is the height of each image in pixels\n",
    "* W is the height of each image in pixels\n",
    "* C is the number of channels (usually 3: R, G, B)\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, which needs spatial understanding of where the pixels are relative to each other. When we input image data into fully connected affine layers, however, we want each data example to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example model itself\n",
    "\n",
    "The first step to training your own model is defining its architecture.\n",
    "\n",
    "Here's an example of a convolutional neural network defined in TensorFlow -- try to understand what each line is doing, remembering that each layer is composed upon the previous layer. We haven't trained anything yet - that'll come next - for now, we want you to understand how everything gets set up. \n",
    "\n",
    "In that example, you see 2D convolutional layers (Conv2d), ReLU activations, and fully-connected layers (Linear). You also see the Hinge loss (multi-class SVM) function, and the SGD optimizer being used. \n",
    "\n",
    "Make sure you understand **why the parameters of the Linear layer are 5408 and 10**. You can refer to the material from [CS231n webpages](http://cs231n.github.io/convolutional-networks/).\n",
    "\n",
    "### TensorFlow Details\n",
    "In TensorFlow, much like in our previous notebooks, we'll first specifically initialize our variables, and then our network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(2e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports many other layer types, loss functions, and optimizers - you will experiment with these next. Here's the official API documentation for these (if any of the parameters used above were unclear, this resource will also be helpful). \n",
    "\n",
    "* Layers, Activations, Loss functions : https://www.tensorflow.org/api_guides/python/nn\n",
    "* Optimizers: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "* BatchNorm: https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm. Note that there are few other implementations of batch normalization layers, e.g., [link 1](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm), [link 2](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on one epoch\n",
    "Define the function to train a model as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, correct_prediction, accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_correct,losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have defined a graph of operations above, in order to execute TensorFlow Graphs, by feeding them input data and computing the results, we first need to create a `tf.Session` object. A session encapsulates the control and state of the TensorFlow runtime. For more information, see the TensorFlow [Getting started](https://www.tensorflow.org/get_started/get_started) guide.\n",
    "\n",
    "Optionally we can also specify a device context such as `/cpu:0` or `/gpu:0`. For documentation on this behavior see [this TensorFlow guide](https://www.tensorflow.org/tutorials/using_gpu). Generally, if your machine has GPU available (with all required drivers) and you install Tensorflow GPU version, Tensorflow will automatically select GPU as the primary device. Otherwise, CPU will be selected as the primary device.\n",
    "\n",
    "You should see a validation loss of around 1 and an accuracy of 0.2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iteration 0: with minibatch training loss = 9.47 and accuracy of 0.078\n",
      "Iteration 100: with minibatch training loss = 2.23 and accuracy of 0.12\n",
      "Iteration 200: with minibatch training loss = 1.65 and accuracy of 0.27\n",
      "Iteration 300: with minibatch training loss = 1.59 and accuracy of 0.19\n",
      "Iteration 400: with minibatch training loss = 1.31 and accuracy of 0.19\n",
      "Iteration 500: with minibatch training loss = 1.37 and accuracy of 0.2\n",
      "Iteration 600: with minibatch training loss = 1.34 and accuracy of 0.22\n",
      "Iteration 700: with minibatch training loss = 1.19 and accuracy of 0.19\n",
      "Epoch 1, Overall loss = 1.56 and accuracy of 0.193\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VHX2+PH3SSeEmtCJ9KLShEgX\nI2IBC669o6vLT9e2TcWyuq5bWN3Vdd39qtjbWtaKBQGBgKKAoPReQu89QEg7vz/unclMMpPMDEwy\nIef1PHnm3jv3zpxJJnPm00VVMcYYY0IRV90BGGOMqTksaRhjjAmZJQ1jjDEhs6RhjDEmZJY0jDHG\nhMyShjHGmJBZ0jAmTCKiItKxuuMwpjpY0jA1mojkisgREcnz+fl3dcflISLdRGSiiOwSkUoHRVlC\nMrHOkoY5EVykqmk+P3dWd0A+CoH3gVuqOxBjjgdLGuaEJSI3ichMEXlWRPaLyHIROdvn/pYiMl5E\n9ojIahH5hc998SLyoIisEZGDIjJPRDJ9Hn6YiKwSkb0i8h8RkUAxqOoKVX0ZWHKMryVORB4WkfUi\nskNE3hCRBu59KSLylojsFpF9IvKDiDTz+R2sdV/DOhG57ljiMMaShjnR9QPWAhnAo8BHItLYve8d\nYBPQErgc+ItPUvkNcA0wAqgP/Bw47PO4FwKnAz2BK4HzovsyuMn9OQtoD6QBnmq4UUADIBNIB24D\njohIXeBfwHBVrQcMBOZHOU5zgrOkYU4En7jfsD0/v/C5bwfwT1UtVNX3gBXABW6pYTBwv6rmq+p8\n4CXgBve6W4GH3ZKCquoCVd3t87hjVXWfqm4ApgG9ovwarwOeUtW1qpoHPABcLSIJOFVg6UBHVS1W\n1XmqesC9rgToJiJ1VHWrqh5TiccYSxrmRHCJqjb0+XnR577N6j8r53qckkVLYI+qHixzXyt3OxNY\nU8FzbvPZPozzzT+aWuLE57EeSACaAW8CE4F3RWSLiDwhIomqegi4CqfksVVEvhCRrlGO05zgLGmY\nE12rMu0NJwFb3J/GIlKvzH2b3e2NQIeqCTEkW4A2PvsnAUXAdrcU9ZiqnoJTBXUhcCOAqk5U1XOA\nFsBy4EWMOQaWNMyJrilwt4gkisgVwMnAl6q6EfgO+KvbkNwDp4fT2+51LwGPi0gncfQQkfRwn9y9\nNgVIcvdTRCS5ksuS3PM8P/E47S+/FpF2IpIG/AV4T1WLROQsEenunncAp7qqWESaicjFbtvGUSAP\nKA73NRjjK6G6AzDmOPhMRHw/DCer6s/c7dlAJ2AXsB243Kdt4hrgeZxv8XuBR1V1snvfU0AyMAmn\nEX054HnMcLQB1vnsH8GpWmpbwTVl2x1+AbyCU0U1A0jBqY66y72/ufs6WuMkhveAt4AmwG9xqq8U\npxH8lxG8BmO8xBZhMicqEbkJuFVVB1d3LMacKKx6yhhjTMgsaRhjjAmZVU8ZY4wJmZU0jDHGhKxG\n957KyMjQtm3bRnTtoUOHqFu37vEN6Diy+I5NLMcXy7GBxXesakJ8y5cv36WqTSJ6AFWtsT99+vTR\nSE2bNi3ia6uCxXdsYjm+WI5N1eI7VjUhPmCuRvi5a9VTxhhjQmZJwxhjTMgsaRhjjAmZJQ1jjDEh\ns6RhjDEmZJY0jDHGhMyShjHGmJBFNWmISEMR+UBElovIMhEZICKNRWSyiKxybxu554qI/EtEVovI\nQhHpHa24fsjdw4erCigoKonWUxhjzAkp2iWNZ4CvVLUr0BNYBowBpqhqJ2CKuw8wHGfdg07AaOC5\naAX14/q9fLamkKISSxrGGBOOqCUNEakPDAFeBlDVAlXdB4wEXndPex24xN0eCbzhDlqcBTQUkRbR\nic25LbG5Go0xJixRm+VWRHoB44ClOKWMecA9wGZVbehz3l5VbSQinwNjVfVb9/gU4H5VnVvmcUfj\nlERo1qxZn3fffTfs2CasK+S9FQU8NyyVOglS+QXVIC8vj7S0tOoOIyiLL3KxHBtYfMeqJsR30UUX\nzVPVrEiuj+aEhQlAb+AuVZ0tIs9QWhUVSKBP73IZTVXH4SQjsrKyNDs7O+zAVsevhRXLGDR4MPVT\nEsO+virk5OQQyWurKhZf5GI5NrD4jlVNiO9YRLNNYxOwSVVnu/sf4CSR7Z5qJ/d2h8/5mT7Xt8ZZ\nu/m4E7d+Sq1JwxhjwhK1pKGq24CNItLFPXQ2TlXVeGCUe2wU8Km7PR640e1F1R/Yr6pboxGbp0ij\n5QsyxhhjKhDt9TTuAt4WkSRgLXAzTqJ6X0RuATYAV7jnfgmMAFYDh91zoyLOzRq2aKExxoQnqklD\nVecDgRpbzg5wrgJ3RDMeD0/1VIllDWOMCUutHBHu6XJrKcMYY8JTS5OG2xBuWcMYY8JSO5OGexut\nMSrGGHOiqp1Jw6qnjDEmIrUyacRZ9ZQxxkSkViYNT/WU9Z4yxpjw1Mqk4S1pVHMcxhhT09TKpOEp\napTYNLfGGBOWWpk0YnNeW2OMiX21MmlYQ7gxxkSmViaN0kWYLGsYY0w4anXSsJRhjDHhqZVJo7R6\nytKGMcaEo1YmDQ/rPGWMMeGplUnDM2GhVVAZY0x4amXSsEWYjDEmMrUyaQieRZiqORBjjKlhamfS\n8PaesqxhjDHhqJVJI847jUj1xmGMMTVNrUwanolErKRhjDHhqZVJwxrCjTEmMrUyadga4cYYE5na\nmTTcW6ueMsaY8NTKpBHnvmoraRhjTHhqZdIoHadhWcMYY8JRK5MGNsutMcZEpFYmDVuEyRhjIhPV\npCEiuSKySETmi8hc91hjEZksIqvc20bucRGRf4nIahFZKCK9oxaXe2tToxtjTHiqoqRxlqr2UtUs\nd38MMEVVOwFT3H2A4UAn92c08Fy0ArJFmIwxJjLVUT01Enjd3X4duMTn+BvqmAU0FJEW0QjAqqeM\nMSYyEs0qGhFZB+zF+VL/gqqOE5F9qtrQ55y9qtpIRD4Hxqrqt+7xKcD9qjq3zGOOximJ0KxZsz7v\nvvtu2HEt3V3MEz/kM6ZvCl0bx0f8+qIpLy+PtLS06g4jKIsvcrEcG1h8x6omxHfRRRfN86n9CUvC\n8Q6ojEGqukVEmgKTRWR5BedKgGPlMpqqjgPGAWRlZWl2dnbYQSWv2Q0/zKJnz14M6JAe9vVVIScn\nh0heW1Wx+CIXy7GBxXesakJ8xyKq1VOqusW93QF8DPQFtnuqndzbHe7pm4BMn8tbA1uiEZe3TcPq\np4wxJixRSxoiUldE6nm2gXOBxcB4YJR72ijgU3d7PHCj24uqP7BfVbdGJTb31lKGMcaEJ5rVU82A\nj93JAROA/6rqVyLyA/C+iNwCbACucM//EhgBrAYOAzdHK7C4OGsIN8aYSEQtaajqWqBngOO7gbMD\nHFfgjmjF48tT0rBpRIwxJjy1ckS4jdMwxpjI1NKk4amesrRhjDHhqJ1Jw721nGGMMeGpnUlDbI1w\nY4yJRK1MGrZGuDHGRKZWJo3SRZiqORBjjKlhamfSsBHhxhgTkdqdNKo3DGOMqXFqZ9LAutwaY0wk\namXSiHNfteUMY4wJT61MGtYQbowxkamdScPbpmFZwxhjwlErk4aN0zDGmMjUyqSBt3rKsoYxxoSj\nViYNCbSwrDHGmErVyqQRJ7YIkzHGRKJWJg1bhMkYYyJTO5OGNYQbY0xEamXS8FZPVXMcxhhT09TK\npOFh1VPGGBOeWpk0vL2nLGcYY0xYKk0aInKPiNQXx8si8qOInFsVwUVLnK3cZ4wxEQmlpPFzVT0A\nnAs0AW4GxkY1qijzlDRs7iljjAlPKEnDU5kzAnhVVRf4HKuRbJyGMcZEJpSkMU9EJuEkjYkiUg8o\niW5Y0WXjNIwxJjIJIZxzC9ALWKuqh0WkMU4VVc1lK/cZY0xEQilpDABWqOo+EbkeeBjYH+oTiEi8\niPwkIp+7++1EZLaIrBKR90QkyT2e7O6vdu9vG/7LCU2cje4zxpiIhJI0ngMOi0hP4D5gPfBGGM9x\nD7DMZ/9vwNOq2gnYi1OSwb3dq6odgafd86KitHoqWs9gjDEnplCSRpE6i2mPBJ5R1WeAeqE8uIi0\nBi4AXnL3BRgKfOCe8jpwibs90t3Hvf9s9/zjTsTWCDfGmEiE0qZxUEQeAG4AzhCReCAxxMf/J07p\nxJNk0oF9qlrk7m8CWrnbrYCNAKpaJCL73fN3+T6giIwGRgM0a9aMnJycEEMplVfgJItVq1aTU7g+\n7OurQl5eXkSvrapYfJGL5djA4jtWNSG+YxFK0rgKuBZnvMY2ETkJeLKyi0TkQmCHqs4TkWzP4QCn\nagj3lR5QHQeMA8jKytLs7Oyyp1Rq/+FCmDqJ9h07kj24XdjXV4WcnBwieW1VxeKLXCzHBhbfsaoJ\n8R2LSqunVHUb8DbQwE0E+aoaSpvGIOBiEckF3sWplvon0FBEPMmqNbDF3d4EZAK49zcA9oT+UkIn\n7qu26iljjAlPKNOIXAnMAa4ArgRmi8jllV2nqg+oamtVbQtcDUxV1euAaYDn+lHAp+72eHcf9/6p\nGqVP9QR3kfBiawk3xpiwhFI99RBwuqruABCRJsDXlDZmh+t+4F0R+RPwE/Cye/xl4E0RWY1Twrg6\nwsevlKfLbZElDWOMCUsoSSPOkzBcuwlzdlxVzQFy3O21QN8A5+TjlGaizlPSKLGkYYwxYQklaXwl\nIhOBd9z9q4AvoxdS9MXHWUnDGGMiUWnSUNV7ReQynIZtAcap6sdRjyyKRATB2jSMMSZcoZQ0UNUP\ngQ+jHEuVihcraRhjTLiCJg0ROUjgOf0EUFWtH7WoqkBcnM1ya4wx4QqaNFQ1pKlCaqp4gaJiSxrG\nGBOOWrlGOECcQHFJjV4WxBhjqlztThpWPWWMMWGptUkjXsR6TxljTJhqbdKIszYNY4wJWyhzT13q\nrrK3X0QOiMhBETlQFcFFk9OmYUnDGGPCEco4jSeAi1R1WaVn1iDx1qZhjDFhC6V6avuJljDArZ6y\nkoYxxoSlosF9l7qbc0XkPeAT4KjnflX9KMqxRVWcQLG1aRhjTFgqqp66yGf7MHCuz74CNTxpiFVP\nGWNMmCoaEX5zVQZS1eKtIdwYY8IWSu+p10Wkoc9+IxF5JbphRZ+1aRhjTPhCaQjvoar7PDuquhc4\nLXohVY04sUWYjDEmXKEkjTgRaeTZEZHGhDileixzpka3uaeMMSYcoXz4/wP4TkQ+wGkAvxL4S1Sj\nqgI2uM8YY8IXysp9b4jIXGAozloal6rq0qhHFmXWpmGMMeGrNGmIyJuqegOwNMCxGitexNo0jDEm\nTKG0aZzquyMi8UCf6IRTdaykYYwx4QuaNETkAXfJ1x4+ExUeBHYAn1ZZhFFibRrGGBO+oElDVf/q\nLvn6pKrWV9V67k+6qj5QhTFGhZU0jDEmfKE0hD/gdrntBKT4HJ8RzcCiLSEOCgusy60xxoQjlIbw\nW4F7gNbAfKA/8D1Ob6oaKzFOKCiypGGMMeEIpSH8HuB0YL2qnoUzGnxnZReJSIqIzBGRBSKyREQe\nc4+3E5HZ7sJO74lIkns82d1f7d7fNuJXFYLEODhqScMYY8ISStLIV9V8cD7YVXU50CWE644CQ1W1\nJ9ALOF9E+gN/A55W1U7AXuAW9/xbgL2q2hF42j0vahLisJKGMcaEKZSkscmdsPATYLKIfApsqewi\ndeS5u4nuj+JUa33gHn8duMTdHunu495/tohISK8iAlY9ZYwx4RMNY00JETkTaAB8paoFIZwfD8wD\nOgL/AZ4EZrmlCUQkE5igqt1EZDFwvqpucu9bA/RT1V1lHnM0MBqgWbNmfd59992Q4/f13pI8JmwU\nXjkvlbjo5aaI5eXlkZaWVt1hBGXxRS6WYwOL71jVhPguuuiieaqaFcn1IU08KCK9gcE4JYWZoSQM\nAFUtBnq5JZWPgZMDneZ5mgru833MccA4gKysLM3Ozg4llHI+XzsJKGTg4CGkJMZH9BjRlJOTQ6Sv\nrSpYfJGL5djA4jtWNSG+YxHKehqP4FQbpQMZwKsi8nA4T+JOrZ6D0/OqoYh4klVrSqu6NgGZ7nMm\n4JRo9oTzPOFIjHNylDWGG2NM6EJp07gGOF1VH1XVR3E++K+r7CIRaeJZvElE6gDDgGXANOBy97RR\nlI4uH+/u494/VcOpOwtTgvvKrV3DGGNCF0r1VC7OoL58dz8ZWBPCdS2A1912jTjgfVX9XESWAu+K\nyJ+An4CX3fNfBt4UkdU4JYyrQ34VEUj0JI1iSxrGGBOqoElDRJ7FaVM4CiwRkcnu/jnAt5U9sKou\nJMAKf6q6Fugb4Hg+cEXIkR+jBE/1VGFxVT2lMcbUeBWVNOa6t/NwGrE9cqIWTRWykoYxxoQvaNJQ\n1deD3XciSLQ2DWOMCVtF1VPvq+qVIrKIwF1fe0Q1sihLineqp44UWPWUMcaEqqLqqXvc2wurIpCq\nlpbo3O45FNKQE2OMMVRcPbXVvV1fdeFUnfrJTkljV97Rao7EGGNqjlAG913qzki732cFvwNVEVw0\n1U8S4gR25llJwxhjQhXKOI0ngItUdVm0g6lKcSI0rpvEzoNW0jDGmFCFMiJ8+4mWMDzqpSRy6GhR\ndYdhjDE1Rigljbki8h7O1Ojer+Wq+lHUoqoiSfFxHC2y3lPGGBOqUJJGfeAwcK7PMQVqftJIiLNx\nGsYYE4ZKk4aq3lwVgVSH5IQ4GxFujDFhqGhw332q+oTPHFR+VPXuqEZWBaykYYwx4amopOFp/J5b\nwTk1WlJCHHnWEG6MMSGraHDfZ+7tCTsHVVK8lTSMMSYclbZpiEgW8BDQxvf8mj73FEByYrwlDWOM\nCUMovafeBu4FFgEn1Ces0+X2hHpJxhgTVaEkjZ2qOj7qkVSDpARLGsYYE45QksajIvISMIUTbHBf\nckIcBTa4zxhjQhZK0rgZ6AokUlo9dUIM7ktOiONAfhGLN++nW6sG1R2OMcbEvFCSRk9V7R71SKpB\nUoIz9daFz35L7tgLqjkaY4yJfaFMWDhLRE6JeiTVICk+lJdvjDHGI5SSxmBglIisw2nTEEBPhC63\n6WnJ3u3C4hISLYkYY0yFQkka50c9imrSJj3Vu33lC9/z8S8HVWM0xhgT+0KZsPCEXO4VoHmDFO/2\nTxv2VWMkxhhTM9Tq+pj2GXURqe4ojDGm5qjVSUNEuP3MDtUdhjHG1Bi1OmkAfo3fXy3eVo2RGGNM\n7Ita0hCRTBGZJiLLRGSJiNzjHm8sIpNFZJV728g9LiLyLxFZLSILRaR3tGLz5btQyG1vzauKpzTG\nmBormiWNIuC3qnoy0B+4wx3vMQaYoqqdcKYmGeOePxzo5P6MBp6LYmylVMvslltvyhhjjCtqSUNV\nt6rqj+72QZxFnVoBIwHPGh2vA5e42yOBN9QxC2goIi2iFZ9HSZkcsWnvEZ6cuNymTDfGmACkKr5Z\ni0hbYAbQDdigqg197turqo1E5HNgrKp+6x6fAtyvqnPLPNZonJIIzZo16/Puu+9GFFNeXh5paWl8\nsLKAz9cWeo9n1otj48ESRvdIZmDLUIaxRIcnvlhl8UUulmMDi+9Y1YT4LrroonmqmhXJ9VH/VBSR\nNOBD4FeqekCC93ENdEegtcnHAeMAsrKyNDs7O6K4cnJyyM7OZnb+cli7hjM6ZfDNql1sPOiUMLqd\negrZPVtG9NjHgye+WGXxRS6WYwOL71jVhPiORVR7T4lIIk7CeNtnKvXtnmon93aHe3wTkOlzeWtg\nSzTjAyhxS1ppyf75MyFOyDtaZNVUxhjjI5q9pwR4GVimqk/53DUeGOVujwI+9Tl+o9uLqj+wX1W3\nRis+D0/tXNmkkXe0iG6PTuSmV+d4j/1j0gq+XbUr2iEZY0zMimZJYxBwAzBUROa7PyOAscA5IrIK\nOMfdB/gSWAusBl4EfhnF2Lw8bTppKf5J49DRIgC+W7MbgKLiEp6duprrX55dFWEZY0xMilqbhtug\nHawB4+wA5ytwR7TiCWZI5ya8+M06zurSlFdn5nqP+24DbN2fX7WBGWNMDKq+7kEx4oxOTVj5p+Hl\n5qDasOew3/6mvUcASE2Kr6rQjDEm5tT6pAGlK/hVZPWOg4DTcF5SosTF2UyHxpjap9bPPRXIwxec\n7Lc/N3cP8zfuByC/sIS73/2pOsIyxphqZ0nDx1ldmvDgiK7cekZ7urWq7z1++fPf8+GPm7z7ny/c\nyt5DBQDkFxYzack2jhQUV3m8xhhT1ax6yserN/f1bjevX4fFmw8EPfe0xycD0KdNI+at38sN/dvw\n+CXdoh6jMcZUJytpBPHYyFNDOm/e+r1A+YbzYAqLS1i361DEcRljTHWypBFEq4Z1eOuWfn7HGtdN\nok5i4N5TvtVTq3ccpO2YL/hudfmBgH/6fCln/T2H71bvYvO+I8c3aGOMiTJLGhUoO+CvX7vGPH1V\nr4Dn5rmDAQG+XubMjDJl+Y5y581auweAa1+azaCxU49XqMYYUyUsaVSgbKmiqERJDtI9d+/hAu/2\nzoNHAchISwZg2oodPDtlFQCJCdZV1xhTc1nSqECb9FR6ZTbk/53ZHnCmEgmWNLbuz+eLhc5UWYs2\nOd1zE+OdBHHzqz/wj8kryS8sJinefuXGmJrLPsEqkJIYzyd3DGJghwzAKWlUNBDwjv/+yPJtB5iT\n61RBHSko9nbNBej6+69YtvVghc85bfkOLv2/md7Zd40xJpZY0ghBgjv6u6i44qQBMPqN0nXGDxUU\ne7vmehwp9B/PcdOrc9hxoHReq7ve+YkfN+zjSBHGGBNzLGmEoGdmQ9qkp/K78zqTnFDx3FO+XW9X\nbq+4VAGQs2InL327DoAJi7Z6G9SLAxQ0dhzMp6Ts+rTGGFOFLGmEIC05gen3nkWfNo0DljSa1ksO\neN1Un95T7ZvUDfr4hwuK2LjnMLe//aP32IR1hX7ntB3zBX3/PIUXv1kbbvjGGHPcWNIIU6CG8Cm/\nPZObB7Wt8Lrszk3p2rxewPvenr2BM56Y5ndswrpCnp++hh0H/adk/2nDPsCZvmTzviMUFJWwx6fd\nxBhjosmSRpgClTRSkxIY3q1FhdfVS0mgXkrgWVuCtXmPnbCczxZs9S4UBXBSeioAt7z+A4PGTuWX\nb8+j9+OTeX76Gubm7mHvoQLOfXo6y7c5U6BMXb6dP4xfEspLi1hxiXoXrTLGnNgsaYTJN2m0aJAC\nQHyceLvXenx252C//fp1EqmXkhj28x0pKPJrPK/nLks7c7WzoqBnIOHYCcu5/Pnvmbx0Oyu35zFu\nulON9fPX5vLad7l+ied4e/zzpZz66EQKi209dWNOdJY0wuRbPfXpnYP48PYBgH8yeenGLLq3buB3\nXb2UBOoHKWlU5Ksl25i/cZ93v6CSD+ZFm50xIk3q+7ez5IVREigsLqHnY5N474cNrNhWeWP+Zwu2\nAJBrc2oZc8KzpBEm38F5Teul0KdNY8A/mQw7pVm56+qnJNLMLZmEY/HmA1z7Yum65AVFJSx2E0Mg\nb85aD8CBMn12r3j+e44WVTx9+9qdeWw/kM/B/CL2Hynk/g8Xcd4/Z1SacDxVZstCSDDGmJrNpkYP\nk5RdF9aVGGCk9+3ZHXguZw3glDTapQfvQRWqF2as5YUZlfegemfOBi7qWdrOsnzbQe7930KeuLwH\nKYnxlJQoJaok+MQ99B/TAz7W4YIi0pKDtcco29z10/cftgZ5Y050VtKI0KW9W/ntB2ogv//8rpx2\nUkPv/e2bpFX6uOedWr6UEinfEgrA+AVbeH76Gg4dLWL0m/Po+NAE730FRcGrvfILAt/32sx1tHvg\nS7a6SSO/sPx5izfvZ+g/cth/pLDcfcaYmseSRgTW/mUE/7iip9+xYHNKeRqHE+Pj6NOmET192jqa\n1kvmzrM6+p3/wHD/pWaPt39+vYrb3prH18u2A7A77ygFRSVs2BO8PeJQQfnqqSW7ivnDZ0v9jvlW\nf+04kI+q8vTklazdeYg56/Ycp1dgjKlOVj0Vgbi48lVUiUGmF3ns4lP542dL6dq8HvFxwqd3Dmbp\nlgNsO3CEoV2bsXHPYf49bbX3/PgAjw3QPqMuubsPcTwGhH+zqnSdjz5/+hqAk1vUD3Y6hwMsZfvk\n3PxyxzwljZH/mcmCjft4cETXYw3VGBNjrKRxnAQrafRp05hP7xxMis8066e0rM/Qrk41VJ2k0uNt\n01O9+wNa+k9XkhAv3oTx8AUnc8/Znco9V7sMp82kcd2ksONftjX40rbP5axh76EC7nrnJ7KfnMas\ntbsDnpdfWIyqssDt7ZWzYieeHBfNLr/GmKpjSeM4iXTK84y0ZJ64rAeTfz2ECfcMISMtmc/vGszN\npyaT1aYRAOl1kxgzvPRb+8AOGd62El+eiRX/WGap2mEnH1s7ydfLtvP3SSv4bMEWcncf5n9zNwU8\n72hRid+YEt+Zej2llcMFRXyxcCt7DhXwwEeLmLc+9GqrkhJl8tLtqCrbD+RzIL+QwuKSqMzHlV9Y\nzGOfLWFfJY3789bvZcKircf9+aNBVVmyJXjPO2NCYdVTx4mnyqpj08obu8u68vRMv/1urRqwa5Xw\nv9sGoFq+OqxVozrsO1L+w2zM8K6s2H7QHZ3+k/d47u5jHz8xeel273ZacpAlbwuL+duE5d792ev2\nkN25CQAHjxbxn2mreXLiCr9r3pmzgZsGtmXm6l1M/s2Z3uPLth7gje/XM7RrU37xxlyeveY08guL\nufeDhfzlZ9158ONFtG5Uh017jzDs5Ga8cEMfnpy4goy0JG4Z3C7o6/h21S7aNalLq4Z1Kny9H/24\nmVdn5hInwu8vPCXoeZc99x0AuWMvqPDxYsH/5m3ivg8W8urNp3NWl6bVHY6poaKWNETkFeBCYIeq\ndnOPNQbeA9oCucCVqrpXnH6szwAjgMPATar6Y6DHjWWf3jGIkxqnHrfHExEC9fBtUCcx4BxYDeok\n8sts/4b11KR4Rg9pT2FxCYLw4MeL/O5/7rrefhMlBrPDXY0Q4PXvnbEgAzuk890ap6oqvW4SH8zz\nL4Golo5cz8svKpcwPF77Ltc9X71dmq9/aTa7DxXwzpwNADzy6WKu69cGcMaTAGza66yx/vWy7Szc\ntI/npzvdmzs0ScP31/bslFXyyfOkAAAdl0lEQVRs2nuE3190Cte/PJu05AQWP3ae9/6New4zbsZa\nuraoR0ZaMued2pwD+U5vryBNTEFt3HOY5g1SAnbBjsTgv02lcd0kxpeZYSCQkhLl0wWbubhnq4Bt\nY0vc8T3rdx2CLsclPFMLRbN66jXg/DLHxgBTVLUTMMXdBxgOdHJ/RgPPRTGuqOmZ2ZBGEbQnRCIp\nvvy3/SY+s+165rla+sfzuTIrk+v6teHaficxekh77zk9WjdgePfgc2ZV9I0d4FfDOgPQvH6K33P7\n8oxgr6jNxGP0m85aJKu2H2R3mUkY9x4u9HYYmLh0W7lrfRe3mrd+L0Ulyvrdh1i94yD/mLyS9+Zu\nZOS/vwWc0fFvfF86tcqkpdt5c9Z6Hvp4Mf/PjeGwO6CxTlLo36v2HCrgjCem8ccyvcqOxaa9R1i4\nKbQqpffmbuTX7y3gze9zA97vqcUL1JHDmFBFraShqjNEpG2ZwyOBbHf7dSAHuN89/oY6/8WzRKSh\niLRQ1ZpRWVxFvn9gKIVFzn9+sfuB171VAz67azB5R/0H4H31qyEBp/VoUMeZ/6pv28a8dFNWufsn\n3HMGw5/5BoBr+p7E7ryjfDLfmSbE08Nq2dYDXH9yEg1TnceqkxRf4TgPcMaIVGby0u38Y9IKnstZ\nQ2pSfMBeWwAb9xwpd8y3rv7f01bTt3k8cybl+J2zZmfp7+ORT5fw1eJt/PcX/dmVd9TvvP2HC73P\nXXadeHAmaPx/b85jYId077Gi4hLvWJQPf9zEmOFdqevz91i9I4+jRcWc2rJBucc7XjyDLMvOejx9\n5U56n9TQ+54JNkDVV0mJIhLauaZ2qeo2jWaeRKCqW0XEU7HaCtjoc94m91i5pCEio3FKIzRr1oyc\nnJyIAsnLy4v42qpQUXxrgZV73YblvIMVvo6cMm3Wm9Y7H2z1Sw7w46yZfveNaJfI9hWlVVU/zZ2D\n5JWO0Th48CCZ9Z3CaSpHmT/vBwCaJeazeJcTz209knl+of+HcDAClG3CfnaqU5ponlRCOAPM3569\nwW9/zraKp0wB+G7Nbr6eOo2FK/2f6JOvZ7B6g/O6X5+xgozD60mMg3pJws4jyphvSqvFPCZNnc7e\nfOfVHC4oZshfJ9EtI54ujZ2kM879nbx2ft1K33vbDpXw+5lH6J5RmrBCea+uzXVex4YN68nJcf51\ndh8p4bfTj9CzSTwLdjq/kzWrVpKTvy7o4+Tl5dH+wS8Z1DKBX/QoLUEWFCtLdxfTq2nkHxsr9xaz\n76jSt7nzGLn7i/nD9/mkxMP/DUslLoQkVZP/d2NBXl7eMV0fKw3hgd4pAbvEqOo4YBxAVlaWZmdn\nR/SEOTk5RHptVagsvm55R/nL7K+5e3gPsnu1CnpeWbkz18HypbRo2Yrs7G4AZHw7mV15BTxwxWAy\nG6fCV18AcObggeybv4WPVy8DoE5qXcaNHshbszbQqWQDw4aeRdMOO+jXLp1hT00nb98Rhg3szfML\nv/d7zjbpqazffZiyrszK5L25G8sdB9CEFMD5cP78rsGs3H6Q37y/oNx5l/ZuxUc/bg759Ze1M60D\nM7f4t/Oc1Lk7xTvXAbvYdli5d0ZpySa7SxNvXL621WnLH6eUVkvtzlembypi+ib/gZGn9R3ET3Nm\nkp2dzartB5m7fi/X9D3J75y2Y5zf/487ShNfRe+F93/YyIAO6bQ6sgHWrKFd23ZkZztdsmev3Q3T\nZ7FiX+m/U9cuXcjuexIH8wtJS04oV5qYOm0acJiZW4p4++7Stp8/jF/Caz/m8ukdWfTMLN97LxhV\n5f9y1nBB9xbc9PccAO4bOwzArcpbR34xnNy7Py0aVNxBAWLzf3f1joM0SUuhQWpiTMbn61gTWlV3\nud0uIi0A3FvP0nabAN8uRK2ByuszarGMtGRyx17AyDASBpQOQlSfnPzCDVmc3bWpd6p3j6SEOEYN\nbMvIXi0BpwttvZREbs/u4O3em92lKXWS4nnjlr7cfXangB8m/do1JnfsBSx45NwysQjj7xzExF8N\nYUT35n73HSoo4tWbTuf+87vSrVWDoK/z0tNah/X6y3rgo0Xljm0/kB90dt+cFTsDHv/j56G1Y6ze\nWfq4lz//PQ98tIinJq3gw3mbaDvmC3YeDFxKU1WWbT3AZwu2sGjTfg7kF3K4oIilWw5w34cLuXrc\nLG/j/cH80ilb1rvLD/tWs4nAzoNH6f6HSYybsZaNew5z7Yuz2HuogKLiEvIK/Z8XYFfeUW+HhY17\nD1NcorwwfU25ySyfn76G12b6l2L2HS7kyYkruP7l0mltPI/r27zi6dhQmW2HSryvNRI7DuZz8b+/\nZcu+0J4vFMOemsE1L846bo8Xy6o6aYwHRrnbo4BPfY7fKI7+wH5rz4iOn53Wikt7t+Keszt7j/Vp\n04iXbzrdO3nhM1f34vxTm1MvJZGkhDjuGup8a61ofF6HJmn85pzOJMbHecesvDzKaTNp6w46rF/H\nv2BbXKL0aN2QLs3rea+59zynW0/3Vg04q2tTbs/uAAQfKZ+eVtrx4PEy41MitXzbQb/eYsE0qx+4\n8b8ilz33PavcqkVPG8i/pq7mt/9zSlG3vjE34HVHi0q4etws7nrnJy7697f0+MMkTnlkIiP+5bQ/\nbd53hD15BX6PO3P1Lu77YCHgdCTwKCgq8bZ/fDJ/C+NmrOW7Nbv56KfNnPHENO6eWloq3HOoAFVl\n/PzS73Brdhziv7PX89cJy+n26ES27j/Cln1HmLNuD2MnLPdOL/PijLV8vnCLN7H4JgVPm5FvIWfj\nnsMs23qAeev3VDgYdMw3R7iuzLxqntd93Uuz2BCgVOtRXKK8N2cjCzft5/Xvc4OeF6r/zd3IvPV7\nAVgaQmcPjw27D/NDbnhT6xQWl1AchTFJ4Ypml9t3cBq9M0RkE/AoMBZ4X0RuATYAV7inf4nT3XY1\nTpfbm6MVV22XmpTAU1f2qvCckb1a+X2z93TvDXWk+Zf3DGbe+r2cfXIzxt85iFPcBvSy1SBFxaX/\nAJ4Puk5N0/jgtgF0ahZ4adyyGqUmcfXpmazakccNA9ry+0+Dr1L49FU9OaNTE7LcqVOCmbA4tO8r\nErBWtXJ/np3PrpRlJMYLhcX+HwILfNZO8fXop0sqnfRx6gqn4L4z7ygvTF/Dp/MDF9bX7DxEB5/x\nRJ7Eu+NAvnfySY9VO/KYvHQ7L39bWnpYvu0AExaX9mC7/8NFzFjpXwIrKi7hz1861ZrdWpWfoiZ3\n9yGapCX7TeG/cnuetwrymr6Z/PXSHuWu88xhtmjzfjo8+CVzHjybeimJbNl3hGy36mvIk87SyZf0\nask/rz7N7/qTH/nK22lDEG58ZQ6C01lg4q+G0CXIkszB3Osm5XANe3o6BUUlYY3v6fTQBAZ3zOCt\nW/tF9JzHSzR7T10T5K6zA5yrwB3RisUcm8zGqTx+STfOC7BOSCAdm9ajY1Pnn69H6+B1377fmg7m\nOx8eDVOTyGrbOOD5Qzo3Yc663ZzZuQktGtRh/IItpKclMfay0g+X6/ufxIyVuzi7ZRGvLi6gUWqi\n91u2IGSkJZOSGEd+YQkDO6Tz1i392Jl3FBFYuS2Pl75dS86KnQE/0D3qpyRwRVYmXyysOLmkJScE\nXYvkhemVT2/vK1jbjy/Ph2HOip1+1WjxceL3u37tu1xmrnbmHysqLuGfX68CYM3O8g2k17002+/a\ns7o08UsYQLmEATDob1O924s3l/8GfsG/vi13zDPOBuCdORtpWi+Fu4Z25Hf/W8CQzk24tHdrrnyh\ntL2suET5ccM+bn9rHkUBvoF/Mn+LX9JQVb9efiu2HfCL/avF2+jSvB5PTVrBG7PW89mdbhufa976\nvXRv1cA7o/XCTf4J3rN654o9xaTl7gn6Pv5y0VZvHHlHi1iwcR8D2qeH1BX629W7Kj0n2mwaEROS\nG/q3oWn98BeRKuv56/tw25lOlZNvaeLPP+vOBT1a0KuCBtbXbz6d5Y8P54UbsvjDxafy4+/PKTeI\n7k+XdGf6vdmc2TqR3LEX8OPvz+H8U/3bS376/bnMuPcsXrnpdOLihGb1U2haL4XBnTK4oHsL4uOE\nP13SjdaNShtlu/jE+vEdgwKOEvf9n3/lpiwy0sqXzIKtS1KRhy+IfObj0UPac22ZhnZwShC+t1C6\ndPCVXRK5tp9zTdnqkFBnPNh+ILQedABndMoI+Lt6ZsoqznhiGp/M38Jv3l9A199PKHfOim0HAiYM\nj90+3anLthdNK9M+5Wnnm7hkO/sOFzJ1+Q7vfS99s5bLnvuOhz8pbQO7+N/+vQ897UZ/nZPP5c/7\ndwbx9UufwbQvfbOW616azdtzNrB4835UlfzCYi589htvYi/Lt3qxOljSMFXq/G7NGTO8Kx/9cqDf\nQMMuzevxn2t7B1yXxCPUMQO+54mIt/Hfc7hOUjwnpaf6TSLpcUVWJssfP5+rTj+Jb+8f6m0nKVal\nuZs0g01B8vldZ3i3G6UmkZzgPP6vh3VmzoNns+CRc/npkXN4OruOt8OA0xsruPdG9/dLNH/+WTdO\nbRl8RuKyOjZJC9oeFEzrtDj+8rPuXNevfLLxtE/56h1gHrRwNExN4ojPmBzfx/OtLgu0XsvfJ62s\n8LH7/Olr3v/BKaVV1uaw73Ahv35vPiu2O50V/jt7A23HfMFtb87jT184VW1T3MQaqM2lfp1Epi4v\n7Yatquw8eBRVDTo/mmfyz1dnruPCZ7/lmSmreH/uRhZvPuA3g8Kn80t7CN79zk/0/+uUamvfiJUu\nt6aW6X1Soyp7rsEd0/lswZaQvyX7ll48I/wT4oS3bu1HnaR4b7IZM7wrv/3fAu8/7ykt6zPrgbNZ\nvHk/PVs3ZNyNfZixahc39G/j9/iNUuK4bUh7bn/7R34+qJ1fVdJJjVMZ2rUpr32Xy4juzenXPp2u\nLeozYfE2/nRJNzIbp9K9VQMWbtrPw58sBuCqCrouD+6U4f0QDFXTVOf1p5dpw7rn7E7exOnrhRuy\nOP3PFbcTVWT/kUI6NE3zjnyvG0FprCL3fbiQ/+SsZvuBir+dL9t6gNk+6754fm9fLSmtjvPMVPDK\nzNxy1xcUlfDz10o7MrR74EsATmlRn92HjvLE5T15PmeN3zWz1jrPt9YdeOqpKgTo3Mx5vz49eSXP\nTCk97onnaFExqWHMWHC8WEnDnPCuzMrkh4eGRTQa25MQMhun0rFpml8p45LTWrHmLyP8zm/eIIVh\npzQjLk5ok163XMLwGN69BfMfOYchnUtLGmd0yiDnd9mcXqYuvEGdRF7/eV9v/XqP1g253udxPY/x\n+CXdaO+WBN66pR+f3DGIlg3r+D2Hrwt7lJ9C5ou7B9O8rvOxEB/n3F6Z1ZrcsRfw63M6M7RrU564\nzL+Bukm9ZD64bUDA56iIpzqnoKiYv13Wg39c0ZMfHhrG4yO7hf1YAFefnskXdw/m9Z/39Ts+7ORm\n5OUXBSypADxxeQ+uysr0SxgV+WrxNh4P0MU6WI+7pVsPsP3AUUa9MofvgywrEMj+I4WMm7HGL2H4\nCvZ6os1KGuaEJyJB58aqzKCOGbRNT+W353YOes5/f9GPjLTwH79hqvNN/uVRWdzyuvMNNS4u8CSV\nFRnRvTn/vbUfAzqkM26G8022RcMUOrjLC5/ZuQnf3HcWq3fkcfNrzij+t2/tR8uGddi2P59xN2ax\nYOM+/jtnA6e0qM90t8bHUzK7Iqt0CJWIcOXpmazZlccL09d6lz3OatuYzMZ12LjnCNf1O6ncCP1A\nOjZNY2CHdK46PZP2TdK809RE8rd64+d9/ZKjZybkpvWSeWlUFvsPF/LY50s4WljCF+5U9o+PPJVT\nWzXgtMyG5BcWQ+DezuXc9ta8sOOLxMQl25m4ZHvQ+/MLK5/1IBqspGFMBTLSksm59yy6Ng/ejjCw\nQwadQ+wiHIinBORpsB7atSk/O60VD18QfEp2XyLCwI4ZiAiZjZzSSNkG98zGqZzVtSlPXt6DD24b\nwKCOGbTLqMsHtw+kcd0kzuralBdvzPJrDxrRvTlzHx5WruQDzrLEuWMv8Ou+3dIdzf3zSia6/Oul\n3QFn3MEDI06mfZPy1Ya+Sbh/+8C9kK7oUzqws2yHCM8YGs9yyw1SE3nqyl6c36259/4bBrSl90mN\nEBHappdvq6nMOSH2JqxM2/TIZsa2pGFMLdW8QQq5Yy/wzjickhjP01f1omUla348fkk3Lu7Z0u/Y\nv6/tzX+u7U2zID3drsjKDNoVtCwRCasE9e9re/PIhafQPqMub9/ajz+OPJV1fx1R7jxPEjpawSSX\n395/lnf7+ev7AM7KlN/cV3r8sZGnBv3A9UxHUrYKx9Mjrmx3at+kMahjOu+O7s/MMUP5+jdDAj7+\nqzedzrPXnMaTl/dg1IA2tG/iXB8swXl4FlbzSE2K987N0L2V8+Vh3sPDvB1C/vyzbvzlZ93p2855\n3AdHdOWZq3sFfG1VxaqnjKmhbujfplybSeO6SVwQoK2iKjSpl+wtZQzqmMGgjhmA0+23VcM6PDre\nGXiZ2bgOHZumVdiV2NPZYHDHDBqmJjHtd9mUqJLZOJU4caZ5r5MYz/u3DeC1mbneD1WPlg2dpHm0\nyP/beCs3aZQtifl2r3771v5+9/16WGee/nolvzmnM09NXul9rSmJ8VyRlckVWZnkHS1iT14BLRum\n8OtXvuaekQNpk55Kp4f8uwnfe14Xrho3i79f0ZMBHdJJS0rgInfK/iev6EFCnJCelsyU35zJ/iOF\ndHMTyTmnNOP3nyzm6r4neUeg5xdVT0nDkoYxJqoeHOEkh4y0ZJrVTyY5IZ6vfVZpDGbJY+d5v3G3\n8+nq+/jAOiS26ISI0LReCved37XctQ3qJHLOKc3KdRtukpbMr4d15oIe/mN34uKEp6/qGXB8yZ1D\nO9KtVX2Gdm3qTRqeJQY80pITvInosk5J3vagX5zRjmEnN6OoRFmwaR/92qez9i8j/Aby/ePKnjw1\naSXtM9K8rzezcarfZHxN6iXz/A1OicszQ0N1VU9Z0jDGVIlwS0DBut62qhdHdlZmwPs8RIQXbyy/\nXoyIcM+wTgGv+VmQyS/j44SzT/Zvv6hfJmkE85BPu5Sn5FV25PfpbRvzzmj/0k1FPKWwo9VUPWVt\nGsYYEyJPD696x3ksSThS3EGjVtIwxpgY9/at/Vi7M69al8xNSXSrp6xNwxhjYlvjukk0rhta77No\n8VRPVVfvKaueMsaYGiQtJYHh3ZoHnQMt2qykYYwxNUj9lESec8euVAcraRhjjAmZJQ1jjDEhs6Rh\njDEmZJY0jDHGhMyShjHGmJBZ0jDGGBMySxrGGGNCZknDGGNMyERVKz8rRonITmB9hJdnALuOYzjH\nm8V3bGI5vliODSy+Y1UT4qurqoEXj69EjU4ax0JE5qpq+bmTY4TFd2xiOb5Yjg0svmN1osdn1VPG\nGGNCZknDGGNMyGpz0hhX3QFUwuI7NrEcXyzHBhbfsTqh46u1bRrGGGPCV5tLGsYYY8JkScMYY0zI\namXSEJHzRWSFiKwWkTHVFMMrIrJDRBb7HGssIpNFZJV728g9LiLyLzfehSLSO8qxZYrINBFZJiJL\nROSeGIsvRUTmiMgCN77H3OPtRGS2G997IpLkHk9291e797eNZnw+ccaLyE8i8nmsxSciuSKySETm\ni8hc91is/H0bisgHIrLcfQ8OiKHYuri/M8/PARH5VazE5z7nr93/i8Ui8o77/3L83nuqWqt+gHhg\nDdAeSAIWAKdUQxxDgN7AYp9jTwBj3O0xwN/c7RHABECA/sDsKMfWAujtbtcDVgKnxFB8AqS524nA\nbPd53weudo8/D9zubv8SeN7dvhp4r4r+xr8B/gt87u7HTHxALpBR5lis/H1fB251t5OAhrESW5k4\n44FtQJtYiQ9oBawD6vi85246nu+9KvnlxtIPMACY6LP/APBANcXSFv+ksQJo4W63AFa42y8A1wQ6\nr4ri/BQ4JxbjA1KBH4F+OKNwE8r+nYGJwAB3O8E9T6IcV2tgCjAU+Nz90Iil+HIpnzSq/e8L1Hc/\n9CTWYgsQ67nAzFiKDydpbAQau++lz4Hzjud7rzZWT3l+qR6b3GOxoJmqbgVwb5u6x6stZre4ehrO\nt/mYic+t+pkP7AAm45Qe96lqUYAYvPG59+8H0qMZH/BP4D6gxN1Pj7H4FJgkIvNEZLR7LBb+vu2B\nncCrbtXeSyJSN0ZiK+tq4B13OybiU9XNwN+BDcBWnPfSPI7je682Jg0JcCzW+x1XS8wikgZ8CPxK\nVQ9UdGqAY1GNT1WLVbUXzjf6vsDJFcRQpfGJyIXADlWd53u4ghiq4+87SFV7A8OBO0RkSAXnVmV8\nCTjVts+p6mnAIZzqnmCq638jCbgY+F9lpwY4Fs33XiNgJNAOaAnUxfkbB4sh7PhqY9LYBGT67LcG\ntlRTLGVtF5EWAO7tDvd4lccsIok4CeNtVf0o1uLzUNV9QA5OfXFDEUkIEIM3Pvf+BsCeKIY1CLhY\nRHKBd3GqqP4ZQ/Ghqlvc2x3AxziJNxb+vpuATao6293/ACeJxEJsvoYDP6rqdnc/VuIbBqxT1Z2q\nWgh8BAzkOL73amPS+AHo5PYmSMIpYo6v5pg8xgOj3O1ROG0JnuM3uj0x+gP7PUXhaBARAV4Glqnq\nUzEYXxMRaehu18H5R1kGTAMuDxKfJ+7LganqVuJGg6o+oKqtVbUtzvtrqqpeFyvxiUhdEann2cap\nm19MDPx9VXUbsFFEuriHzgaWxkJsZVxDadWUJ45YiG8D0F9EUt3/Y8/v7/i996qiwSjWfnB6NKzE\nqQd/qJpieAenzrEQJ9vfglOXOAVY5d42ds8V4D9uvIuArCjHNhiniLoQmO/+jIih+HoAP7nxLQYe\ncY+3B+YAq3GqDZLd4ynu/mr3/vZV+HfOprT3VEzE58axwP1Z4vkfiKG/by9grvv3/QRoFCuxuc+Z\nCuwGGvgci6X4HgOWu/8bbwLJx/O9Z9OIGGOMCVltrJ4yxhgTIUsaxhhjQmZJwxhjTMgsaRhjjAmZ\nJQ1jjDEhs6RhThgicrFUMmuxiLQUkQ/c7ZtE5N9hPseDIZzzmohcXtl50SIiOSKSVV3Pb05sljTM\nCUNVx6vq2ErO2aKqx/KBXmnSqMl8Rg0bE5AlDRPzRKStOGsrvOSuEfC2iAwTkZnu+gB93fO8JQf3\n2/6/ROQ7EVnr+ebvPtZin4fPFJGvxFlf5VGf5/zEncxviWdCPxEZC9QRZx2Ft91jN4qzTsICEXnT\n53GHlH3uAK9pmYi86D7HJHd0u19JQUQy3OlIPK/vExH5TETWicidIvIbcSb2myUijX2e4nr3+Rf7\n/H7qirOOyw/uNSN9Hvd/IvIZMOlY/lbmxGdJw9QUHYFncEaDdwWuxRm5/juCf/tv4Z5zIRCsBNIX\nuA5nFPIVPtU6P1fVPkAWcLeIpKvqGOCIqvZS1etE5FTgIWCoqvYE7gnzuTsB/1HVU4F9wGUV/QJc\n3XBee1/gz8BhdSb2+x640ee8uqo6EGe9hFfcYw/hTBNxOnAW8KQ7jQg402WPUtWhIcRgajFLGqam\nWKeqi1S1BGfqiynqTGewCGddkkA+UdUSVV0KNAtyzmRV3a2qR3AmdxvsHr9bRBYAs3AmdOsU4Nqh\nwAequgtAVX0negvludep6nx3e14Fr8PXNFU9qKo7caax/sw9Xvb38I4b0wygvjtX17nAGHGmlM/B\nmULiJPf8yWXiNyYgq780NcVRn+0Sn/0Sgr+Pfa8JNAU0lJ8GWkUkG2cSxAGqelhEcnA+YMuSANeH\n89y+5xQDddztIkq/0JV93lB/D+VelxvHZaq6wvcOEemHMwW5MZWykoap7c4RZ33nOsAlwEyc6aH3\nugmjK8606x6F4kwbD87EdFeKSDo4a2wfp5hygT7udqSN9lcBiMhgnJlV9+Os0naXO/spInLaMcZp\naiFLGqa2+xZnJtD5wIeqOhf4CkgQkYXA4zhVVB7jgIUi8raqLsFpV5juVmU9xfHxd+B2EfkOyIjw\nMfa61z+PM4MyOK8lESf+xe6+MWGxWW6NMcaEzEoaxhhjQmZJwxhjTMgsaRhjjAmZJQ1jjDEhs6Rh\njDEmZJY0jDHGhMyShjHGmJD9f9TQY6SGW9+PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17fa7d630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 1.12 and accuracy of 0.226\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,plot_losses=True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.47912791146985734&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_2&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.05914847552776337\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.05914847552776337\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/max&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/mul&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Wconv1&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Wconv1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.3061862289905548\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.3061862289905548\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/max&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/mul&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bconv1&quot;\\n  input: &quot;bconv1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bconv1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\025\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.03327791765332222\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.03327791765332222\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;W1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;W1/Initializer/random_uniform/max&quot;\\n  input: &quot;W1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;W1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;W1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;W1/Initializer/random_uniform/mul&quot;\\n  input: &quot;W1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5408\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;W1&quot;\\n  input: &quot;W1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;W1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;b1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;b1/Initializer/random_uniform/max&quot;\\n  input: &quot;b1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;b1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;b1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;b1/Initializer/random_uniform/mul&quot;\\n  input: &quot;b1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;b1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Wconv1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2D&quot;\\n  input: &quot;bconv1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377 \\\\025\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Relu&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;W1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;b1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;Placeholder_1&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/mul/x&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hinge_loss/mul&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  input: &quot;hinge_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;hinge_loss/Sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;hinge_loss/ToFloat_3/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/Mul_1&quot;\\n  input: &quot;hinge_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  input: &quot;hinge_loss/num_present/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/num_present/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/num_present/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/num_present/Equal&quot;\\n  input: &quot;hinge_loss/num_present/zeros_like&quot;\\n  input: &quot;hinge_loss/num_present/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/num_present/Select&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  input: &quot;hinge_loss/num_present/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/Sum&quot;\\n  input: &quot;hinge_loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Greater/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  input: &quot;hinge_loss/Greater/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  input: &quot;hinge_loss/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/ones_like_1/Shape&quot;\\n  input: &quot;hinge_loss/ones_like_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;hinge_loss/ones_like_1&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;hinge_loss/Sum_1&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/value&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;hinge_loss/div&quot;\\n  input: &quot;hinge_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;hinge_loss/value&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/value_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/Select_1&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/value_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;hinge_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Neg&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv_1&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/num_present/Select&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Neg&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;W1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Wconv1/read&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/Conv2D_grad/ShapeN&quot;\\n  input: &quot;Wconv1/read&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;gradients/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.00019999999494757503\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_Wconv1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;Wconv1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_bconv1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;bconv1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_W1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;W1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_b1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_Wconv1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_bconv1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_W1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_b1/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Wconv1/Assign&quot;\\n  input: &quot;^bconv1/Assign&quot;\\n  input: &quot;^W1/Assign&quot;\\n  input: &quot;^b1/Assign&quot;\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax_1/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax_1&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;ArgMax_1/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal_1&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax_1&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_2&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast_1&quot;\\n  input: &quot;Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.47912791146985734&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard for Visualization\n",
    "\n",
    "Tensorflow provides a very useful tool: Tensorboard. This is very helpful to visualize the training loss, accuray, filters,...\n",
    "\n",
    "Here is a good video about Tensorboard: https://www.youtube.com/watch?v=eBbEDRsCmv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "    variable_summaries(Wconv1)\n",
    "    variable_summaries(W1)\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(2e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_with_tensorboard(session, predict, loss_value, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, tensorboard_writer=None):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    tf.summary.scalar(\"cost\", loss_value)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        batch_count = int(math.ceil(Xd.shape[0]/batch_size))\n",
    "        for i in range(batch_count):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            \n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            if training_now:\n",
    "                _, summary = session.run([training, summary_op],feed_dict=feed_dict)\n",
    "                # write log\n",
    "                tensorboard_writer.add_summary(summary, e * batch_count + i)\n",
    "            else:\n",
    "                summary = session.run(summary_op, feed_dict=feed_dict)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer\n",
      "Training\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=logs/train \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "# define SGD optimizer\n",
    "print('SGD optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter('logs/train', graph=tf.get_default_graph())\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model_with_tensorboard(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,\n",
    "                               tensorboard_writer=train_writer)\n",
    "\n",
    "# tensorboard --logdir=logs/train\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=logs/train \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "# NOTE: In Window, you may not able to run the Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "\n",
    "You are going to see [ADAM optimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) being used. Now, we will compare the training loss curves of a model with SGD and ADAM optimizers.\n",
    "\n",
    "You can try other optimizers, e.g., [SGD+Momentum](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer), [RMSprop](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer), [Adagrad](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer), [Adadelta](https://www.tensorflow.org/api_docs/python/tf/train/AdadeltaOptimizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 9.56 and accuracy of 0.047\n",
      "Iteration 100: with minibatch training loss = 2.43 and accuracy of 0.16\n",
      "Iteration 200: with minibatch training loss = 1.99 and accuracy of 0.14\n",
      "Iteration 300: with minibatch training loss = 2.07 and accuracy of 0.12\n",
      "Iteration 400: with minibatch training loss = 1.32 and accuracy of 0.27\n",
      "Iteration 500: with minibatch training loss = 1.59 and accuracy of 0.16\n",
      "Iteration 600: with minibatch training loss = 1.51 and accuracy of 0.19\n",
      "Iteration 700: with minibatch training loss = 1.41 and accuracy of 0.22\n",
      "Epoch 1, Overall loss = 1.89 and accuracy of 0.175\n",
      "Validation\n",
      "Epoch 1, Overall loss = 1.37 and accuracy of 0.214\n",
      "==========================================================\n",
      "\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 7.96 and accuracy of 0.14\n",
      "Iteration 100: with minibatch training loss = 1.34 and accuracy of 0.19\n",
      "Iteration 200: with minibatch training loss = 1.16 and accuracy of 0.23\n",
      "Iteration 300: with minibatch training loss = 1 and accuracy of 0.27\n",
      "Iteration 400: with minibatch training loss = 0.842 and accuracy of 0.25\n",
      "Iteration 500: with minibatch training loss = 0.718 and accuracy of 0.31\n",
      "Iteration 600: with minibatch training loss = 0.841 and accuracy of 0.27\n",
      "Iteration 700: with minibatch training loss = 0.708 and accuracy of 0.31\n",
      "Epoch 1, Overall loss = 1.1 and accuracy of 0.264\n",
      "Validation\n",
      "Epoch 1, Overall loss = 0.673 and accuracy of 0.308\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18480dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "print('SGD optimizer')\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, sgd_losses = run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "\n",
    "print(\"==========================================================\\n\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses = run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "    \n",
    "plt.plot(sgd_losses, label='SGD')\n",
    "plt.plot(adam_losses, label='ADAM')\n",
    "# plt.plot(adam_losses_batchnorm, label='ADAM+BatchNorm')\n",
    "# plt.ylim( (0, 100) ) \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Epoch 1 Loss')\n",
    "plt.xlabel('minibatch number')\n",
    "plt.ylabel('minibatch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go Deeper\n",
    "\n",
    "In the previous exercises, you are required to implement different functions, e.g., affine, relu, conv2d, ... which serve as basic module to build a Deep Neuron Network. Similarly, we provide the basic modules for Tensorflow in `libs/tf_layers.py`.\n",
    "\n",
    "**NOTE:** In this exercise, you are welcome to change the block functions in `libs/tf_layers.py` to fit your needs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a deep network\n",
    "def deep_model(X, y, batchnorm=False, name=None):\n",
    "    output = Conv2D(X, 3, 7, 8, name=name+'_conv1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu1')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN1')\n",
    "    output = Conv2D(output, 8, 7, 8, name=name+'_conv2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu2')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN2')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool1')\n",
    "    output = Conv2D(output, 8, 7, 16, name=name+'_conv3')\n",
    "    output = tf.nn.relu(output, name=name+'_relu3')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN3')\n",
    "    output = Conv2D(output, 16, 7, 16, name=name+'_conv4')\n",
    "    \n",
    "    # Here is another way of defining a name for a layer\n",
    "    with tf.variable_scope(name+'_relu4'):\n",
    "#         output = tf.nn.relu(output, name=name+'_relu4')\n",
    "        output = tf.nn.relu(output)\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN4')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool2')\n",
    "    output = tf.reshape(output, [-1, 16*8*8], name=name+'_flatten')\n",
    "    output = FullyConnected(output, 16*8*8, 100, name=name+'_fc1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu5')\n",
    "    output = FullyConnected(output, 100, 100, name=name+'_fc2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu6')\n",
    "    output = FullyConnected(output, 100, 10, name=name+'_fc3')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now see the benefit of using **batch normalization** layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 0.922 and accuracy of 0.078\n",
      "Iteration 100: with minibatch training loss = 0.273 and accuracy of 0.16\n",
      "Iteration 200: with minibatch training loss = 0.253 and accuracy of 0.22\n",
      "Iteration 300: with minibatch training loss = 0.24 and accuracy of 0.28\n",
      "Iteration 400: with minibatch training loss = 0.231 and accuracy of 0.31\n",
      "Iteration 500: with minibatch training loss = 0.223 and accuracy of 0.41\n",
      "Iteration 600: with minibatch training loss = 0.224 and accuracy of 0.31\n",
      "Iteration 700: with minibatch training loss = 0.229 and accuracy of 0.33\n",
      "Epoch 1, Overall loss = 0.25 and accuracy of 0.28\n",
      "Validation\n",
      "Epoch 1, Overall loss = 0.217 and accuracy of 0.364\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlNf+D5n0z+lyejKsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181dcecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out_deep2 = deep_model(X,y, True, name='deep2')\n",
    "# define our loss\n",
    "total_loss_deep2 = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out_deep2)\n",
    "mean_loss = tf.reduce_mean(total_loss_deep2)\n",
    "\n",
    "print(\"==========================================================\\n\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)\n",
    "    \n",
    "plt.plot(sgd_losses, label='SGD')\n",
    "plt.plot(adam_losses, label='ADAM')\n",
    "plt.plot(adam_losses_batchnorm, label='ADAM+BatchNorm')\n",
    "plt.ylim( (0, 100) ) \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Epoch 1 Loss')\n",
    "plt.xlabel('minibatch number')\n",
    "plt.ylabel('minibatch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More epochs\n",
    "Train the model with more epochs to see how good performance it can achieve.\n",
    "\n",
    "**NOTE:** If you run this on a CPU, it will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 1.45 and accuracy of 0.17\n",
      "Iteration 100: with minibatch training loss = 0.281 and accuracy of 0.23\n",
      "Iteration 200: with minibatch training loss = 0.263 and accuracy of 0.28\n",
      "Iteration 300: with minibatch training loss = 0.232 and accuracy of 0.3\n",
      "Iteration 400: with minibatch training loss = 0.229 and accuracy of 0.36\n",
      "Iteration 500: with minibatch training loss = 0.225 and accuracy of 0.25\n",
      "Iteration 600: with minibatch training loss = 0.235 and accuracy of 0.38\n",
      "Iteration 700: with minibatch training loss = 0.225 and accuracy of 0.31\n",
      "Epoch 1, Overall loss = 0.265 and accuracy of 0.284\n",
      "Iteration 800: with minibatch training loss = 0.212 and accuracy of 0.42\n",
      "Iteration 900: with minibatch training loss = 0.221 and accuracy of 0.41\n",
      "Iteration 1000: with minibatch training loss = 0.208 and accuracy of 0.39\n",
      "Iteration 1100: with minibatch training loss = 0.212 and accuracy of 0.41\n",
      "Iteration 1200: with minibatch training loss = 0.22 and accuracy of 0.33\n",
      "Iteration 1300: with minibatch training loss = 0.198 and accuracy of 0.5\n",
      "Iteration 1400: with minibatch training loss = 0.211 and accuracy of 0.38\n",
      "Iteration 1500: with minibatch training loss = 0.203 and accuracy of 0.41\n",
      "Epoch 2, Overall loss = 0.476 and accuracy of 0.404\n",
      "Iteration 1600: with minibatch training loss = 0.212 and accuracy of 0.34\n",
      "Iteration 1700: with minibatch training loss = 0.2 and accuracy of 0.44\n",
      "Iteration 1800: with minibatch training loss = 0.202 and accuracy of 0.42\n",
      "Iteration 1900: with minibatch training loss = 0.206 and accuracy of 0.48\n",
      "Iteration 2000: with minibatch training loss = 0.202 and accuracy of 0.55\n",
      "Iteration 2100: with minibatch training loss = 0.206 and accuracy of 0.44\n",
      "Iteration 2200: with minibatch training loss = 0.199 and accuracy of 0.47\n",
      "Epoch 3, Overall loss = 0.677 and accuracy of 0.449\n",
      "Iteration 2300: with minibatch training loss = 0.194 and accuracy of 0.42\n",
      "Iteration 2400: with minibatch training loss = 0.206 and accuracy of 0.38\n",
      "Iteration 2500: with minibatch training loss = 0.184 and accuracy of 0.53\n",
      "Iteration 2600: with minibatch training loss = 0.205 and accuracy of 0.42\n",
      "Iteration 2700: with minibatch training loss = 0.182 and accuracy of 0.58\n",
      "Iteration 2800: with minibatch training loss = 0.178 and accuracy of 0.56\n",
      "Iteration 2900: with minibatch training loss = 0.166 and accuracy of 0.62\n",
      "Iteration 3000: with minibatch training loss = 0.214 and accuracy of 0.45\n",
      "Epoch 4, Overall loss = 0.87 and accuracy of 0.486\n",
      "Iteration 3100: with minibatch training loss = 0.188 and accuracy of 0.48\n",
      "Iteration 3200: with minibatch training loss = 0.203 and accuracy of 0.42\n",
      "Iteration 3300: with minibatch training loss = 0.187 and accuracy of 0.47\n",
      "Iteration 3400: with minibatch training loss = 0.194 and accuracy of 0.5\n",
      "Iteration 3500: with minibatch training loss = 0.173 and accuracy of 0.56\n",
      "Iteration 3600: with minibatch training loss = 0.187 and accuracy of 0.5\n",
      "Iteration 3700: with minibatch training loss = 0.188 and accuracy of 0.44\n",
      "Iteration 3800: with minibatch training loss = 0.173 and accuracy of 0.55\n",
      "Epoch 5, Overall loss = 1.05 and accuracy of 0.519\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ceca0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 0.174 and accuracy of 0.557\n"
     ]
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out_deep2 = deep_model(X,y, True, name='deep2')\n",
    "# define our loss\n",
    "total_loss_deep2 = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out_deep2)\n",
    "mean_loss = tf.reduce_mean(total_loss_deep2)\n",
    "\n",
    "print(\"==========================================================\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,5,64,100,train_step,True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a _GREAT_ model on CIFAR-10!\n",
    "\n",
    "### Things you should try:\n",
    "- **Filter size**: Above we used 7x7; bigger filters captures more information but smaller filters may be more computationally efficient.\n",
    "- **Number of filters**: Above we used 32 (or less) filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Use TensorFlow Scope**: Use TensorFlow scope and/or [tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers) to make it easier to write deeper networks. See [this tutorial](https://www.tensorflow.org/tutorials/layers) for how to use `tf.layers`. \n",
    "- **Use Learning Rate Decay**: [As the notes point out](http://cs231n.github.io/neural-networks-3/#anneal), decaying the learning rate might help the model converge. Feel free to decay every epoch, when loss doesn't change over an entire epoch, or any other heuristic you find appropriate. See the [Tensorflow documentation](https://www.tensorflow.org/versions/master/api_guides/python/train#Decaying_the_learning_rate) for learning rate decay.\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use [Dropout as in the TensorFlow MNIST tutorial](https://www.tensorflow.org/get_started/mnist/pros).\n",
    "\n",
    "**NOTE:**\n",
    "* In this exercise, you are welcome to change the block functions in `libs/tf_layers.py` to fit your needs the best.\n",
    "* Softmax cross-entropy loss: [tf.losses.softmax_cross_entropy](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/losses/softmax_cross_entropy)\n",
    "* SVM loss: [tf.losses.hinge_loss](https://www.tensorflow.org/api_docs/python/tf/losses/hinge_loss)\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should **see improvement within a few hundred iterations.**\n",
    "- Remember the **coarse-to-fine** approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should **use the validation set for hyperparameter search**, and we'll save the test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "\n",
    "\n",
    "### What we expect\n",
    "At the very least, you should be able to train a ConvNet that gets at **>= 60% accuracy on the validation set**. This is just a lower bound - if you are careful it should be possible to get accuracies much higher than that! Extra credit points will be awarded for particularly high-scoring models or unique approaches.\n",
    "\n",
    "You should use the space below to experiment and train your network. The final cell in this notebook should contain the training and validation set accuracies for your final trained network.\n",
    "\n",
    "Have fun and happy training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these; however they would be good things to try for extra credit.\n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum, RMSprop, and Adam; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "If you do decide to implement something extra, clearly describe it in the \"Extra Credit Description\" cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feel free to play with this cell\n",
    "# You can implement the model in a seperate python file.\n",
    "\n",
    "def my_model(X,y,is_training):\n",
    "    batchnorm = True\n",
    "    name = 'myModel'\n",
    "    output = Conv2D(X, 3, 7, 8, name=name+'_conv1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu1')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN1')\n",
    "    output = Conv2D(output, 8, 7, 8, name=name+'_conv2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu2')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN2')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool1')\n",
    "    output = Conv2D(output, 8, 7, 16, name=name+'_conv3')\n",
    "    output = tf.nn.relu(output, name=name+'_relu3')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN3')\n",
    "    output = Conv2D(output, 16, 7, 16, name=name+'_conv4')\n",
    "    \n",
    "    # Here is another way of defining a name for a layer\n",
    "    with tf.variable_scope(name+'_relu4'):\n",
    "#         output = tf.nn.relu(output, name=name+'_relu4')\n",
    "        output = tf.nn.relu(output)\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN4')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool2')\n",
    "    output = tf.reshape(output, [-1, 16*8*8], name=name+'_flatten')\n",
    "    output = FullyConnected(output, 16*8*8, 100, name=name+'_fc1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu5')\n",
    "    output = FullyConnected(output, 100, 100, name=name+'_fc2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu6')\n",
    "    output = FullyConnected(output, 100, 10, name=name+'_fc3')\n",
    "    return output\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = my_model(X,y,is_training)\n",
    "mean_loss = None\n",
    "optimizer = None\n",
    "\n",
    "print(\"==========================================================\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,5,64,100,train_step,True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feel free to play with this cell\n",
    "# This default code creates a session\n",
    "# and trains your model for 10 epochs\n",
    "# then prints the validation set accuracy\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Training')\n",
    "run_model(sess,y_out,mean_loss,X_train,y_train,10,64,100,train_step,True)\n",
    "print('Validation')\n",
    "run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test your model here, and make sure \n",
    "# the output of this cell is the accuracy\n",
    "# of your best model on the training and val sets\n",
    "# We're looking for >= 60% accuracy on Validation\n",
    "print('Training')\n",
    "run_model(sess,y_out,mean_loss,X_train,y_train,1,64)\n",
    "print('Validation')\n",
    "run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set - DO THIS ONLY ONCE\n",
    "Now that we've gotten a result that we're happy with, we test our final model on the test set. This would be the score we would achieve on a competition. Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test')\n",
    "run_model(sess,y_out,mean_loss,X_test,y_test,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit Description\n",
    "Briefly describe what you did here.\n",
    "\n",
    "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tell us here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
