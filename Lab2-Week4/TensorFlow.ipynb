{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's this TensorFlow business?\n",
    "\n",
    "You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "For the last part of this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, TensorFlow (or PyTorch, if you switch over to that notebook)\n",
    "\n",
    "#### What is it?\n",
    "TensorFlow is a system for executing computational graphs over Tensor objects, with native support for performing backpropogation for its Variables. In it, we work with Tensors which are n-dimensional arrays analogous to the numpy ndarray.\n",
    "\n",
    "#### Why?\n",
    "\n",
    "* Our code will now run on GPUs! Much faster training. Writing your own modules to run on GPUs is beyond the scope of this class, unfortunately.\n",
    "* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants, e.g., TensorFlow. This very excellent framework will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* We want you to be exposed to the sort of deep learning code you might run into in academia or industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acknowledgement: This exercise is adapted from [Stanford CS231n](http://cs231n.stanford.edu/index.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How will I learn TensorFlow?\n",
    "\n",
    "TensorFlow has many excellent tutorials available, including those from [Google themselves](https://www.tensorflow.org/get_started/get_started).\n",
    "\n",
    "Otherwise, this notebook will walk you through much of what you need to do to train models in TensorFlow. See the end of the notebook for some links to helpful tutorials if you want to learn more or need further clarification on topics that aren't fully explained here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from libs.tf_layers import *\n",
    "from libs.vis_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from libs.data_utils import load_CIFAR10\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'libs/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model\n",
    "\n",
    "### Some useful utilities\n",
    "\n",
    ". Remember that our image data is initially N x H x W x C, where:\n",
    "* N is the number of datapoints (mini-batch size)\n",
    "* H is the height of each image in pixels\n",
    "* W is the height of each image in pixels\n",
    "* C is the number of channels (usually 3: R, G, B)\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, which needs spatial understanding of where the pixels are relative to each other. When we input image data into fully connected affine layers, however, we want each data example to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example model itself\n",
    "\n",
    "The first step to training your own model is defining its architecture.\n",
    "\n",
    "Here's an example of a convolutional neural network defined in TensorFlow -- try to understand what each line is doing, remembering that each layer is composed upon the previous layer. We haven't trained anything yet - that'll come next - for now, we want you to understand how everything gets set up. \n",
    "\n",
    "In that example, you see 2D convolutional layers (Conv2d), ReLU activations, and fully-connected layers (Linear). You also see the Hinge loss (multi-class SVM) function, and the SGD optimizer being used. \n",
    "\n",
    "Make sure you understand **why the parameters of the Linear layer are 5408 and 10**. You can refer to the material from [CS231n webpages](http://cs231n.github.io/convolutional-networks/).\n",
    "\n",
    "### TensorFlow Details\n",
    "In TensorFlow, much like in our previous notebooks, we'll first specifically initialize our variables, and then our network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(2e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports many other layer types, loss functions, and optimizers - you will experiment with these next. Here's the official API documentation for these (if any of the parameters used above were unclear, this resource will also be helpful). \n",
    "\n",
    "* Layers, Activations, Loss functions : https://www.tensorflow.org/api_guides/python/nn\n",
    "* Optimizers: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "* BatchNorm: https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm. Note that there are few other implementations of batch normalization layers, e.g., [link 1](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm), [link 2](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on one epoch\n",
    "Define the function to train a model as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, correct_prediction, accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_correct,losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have defined a graph of operations above, in order to execute TensorFlow Graphs, by feeding them input data and computing the results, we first need to create a `tf.Session` object. A session encapsulates the control and state of the TensorFlow runtime. For more information, see the TensorFlow [Getting started](https://www.tensorflow.org/get_started/get_started) guide.\n",
    "\n",
    "Optionally we can also specify a device context such as `/cpu:0` or `/gpu:0`. For documentation on this behavior see [this TensorFlow guide](https://www.tensorflow.org/tutorials/using_gpu). Generally, if your machine has GPU available (with all required drivers) and you install Tensorflow GPU version, Tensorflow will automatically select GPU as the primary device. Otherwise, CPU will be selected as the primary device.\n",
    "\n",
    "You should see a validation loss of around 1 and an accuracy of 0.2 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iteration 0: with minibatch training loss = 8.04 and accuracy of 0.094\n",
      "Iteration 100: with minibatch training loss = 1.95 and accuracy of 0.094\n",
      "Iteration 200: with minibatch training loss = 1.51 and accuracy of 0.12\n",
      "Iteration 300: with minibatch training loss = 1.4 and accuracy of 0.23\n",
      "Iteration 400: with minibatch training loss = 1.25 and accuracy of 0.28\n",
      "Iteration 500: with minibatch training loss = 1.3 and accuracy of 0.23\n",
      "Iteration 600: with minibatch training loss = 1.25 and accuracy of 0.22\n",
      "Iteration 700: with minibatch training loss = 1.09 and accuracy of 0.25\n",
      "Epoch 1, Overall loss = 1.46 and accuracy of 0.191\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0lBKKRUwTRpKKaUC9v+KgC3BFeQ8rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f535c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 1.06 and accuracy of 0.218\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,plot_losses=True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.20301172493953412&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_2&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\007\\\\000\\\\000\\\\000\\\\007\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.05914847552776337\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.05914847552776337\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/max&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/mul&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 7\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Wconv1&quot;\\n  input: &quot;Wconv1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Wconv1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Wconv1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.3061862289905548\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.3061862289905548\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/max&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/mul&quot;\\n  input: &quot;bconv1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;bconv1&quot;\\n  input: &quot;bconv1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;bconv1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;bconv1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\025\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.03327791765332222\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.03327791765332222\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;W1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;W1/Initializer/random_uniform/max&quot;\\n  input: &quot;W1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;W1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;W1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;W1/Initializer/random_uniform/mul&quot;\\n  input: &quot;W1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5408\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;W1&quot;\\n  input: &quot;W1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;W1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;b1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;b1/Initializer/random_uniform/max&quot;\\n  input: &quot;b1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;b1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;b1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;b1/Initializer/random_uniform/mul&quot;\\n  input: &quot;b1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;b1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Wconv1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Conv2D&quot;\\n  input: &quot;bconv1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377 \\\\025\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Relu&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;W1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;b1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;Placeholder_1&quot;\\n  input: &quot;one_hot/depth&quot;\\n  input: &quot;one_hot/on_value&quot;\\n  input: &quot;one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/mul/x&quot;\\n  input: &quot;one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hinge_loss/mul&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  input: &quot;hinge_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;hinge_loss/Sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;hinge_loss/ToFloat_3/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/Mul_1&quot;\\n  input: &quot;hinge_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  input: &quot;hinge_loss/num_present/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/num_present/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/num_present/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/num_present/Equal&quot;\\n  input: &quot;hinge_loss/num_present/zeros_like&quot;\\n  input: &quot;hinge_loss/num_present/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^hinge_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/num_present/Select&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/num_present&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  input: &quot;hinge_loss/num_present/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;hinge_loss/Sum&quot;\\n  input: &quot;hinge_loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Greater/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  input: &quot;hinge_loss/Greater/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  input: &quot;hinge_loss/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/ones_like_1&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;hinge_loss/ones_like_1/Shape&quot;\\n  input: &quot;hinge_loss/ones_like_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;hinge_loss/ones_like_1&quot;\\n  input: &quot;hinge_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;hinge_loss/Sum_1&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^hinge_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hinge_loss/value&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;hinge_loss/div&quot;\\n  input: &quot;hinge_loss/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;hinge_loss/value&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Greater&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/zeros_like&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/value_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/Select_1&quot;\\n  input: &quot;^gradients/hinge_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/value_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;hinge_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Neg&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv_1&quot;\\n  input: &quot;hinge_loss/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/div_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/div_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/div_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/Select_1&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;hinge_loss/Equal&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/zeros_like&quot;\\n  input: &quot;gradients/hinge_loss/div_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/Select_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/Select&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Select_grad/Select&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/Select_1&quot;\\n  input: &quot;^gradients/hinge_loss/Select_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Select_grad/Select_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_1_grad/Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  input: &quot;hinge_loss/ToFloat_3/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  input: &quot;gradients/hinge_loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Select_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  input: &quot;hinge_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/num_present/Select&quot;\\n  input: &quot;gradients/hinge_loss/num_present_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/num_present/broadcast_weights_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/hinge_loss/num_present/broadcast_weights/ones_like_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;hinge_loss/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Neg&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/mul&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hinge_loss/Sub&quot;\\n  input: &quot;gradients/hinge_loss/Sub_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/mul_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Sum_1&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/hinge_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/hinge_loss/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/hinge_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;W1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Conv2D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Relu_grad/ReluGrad&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;Wconv1/read&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;gradients/Conv2D_grad/ShapeN&quot;\\n  input: &quot;Wconv1/read&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;gradients/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^gradients/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.00019999999494757503\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_Wconv1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;Wconv1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Wconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_bconv1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;bconv1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@bconv1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_W1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;W1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_b1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;b1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_Wconv1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_bconv1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_W1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_b1/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Wconv1/Assign&quot;\\n  input: &quot;^bconv1/Assign&quot;\\n  input: &quot;^W1/Assign&quot;\\n  input: &quot;^b1/Assign&quot;\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax_1/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax_1&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;ArgMax_1/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal_1&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax_1&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_2&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast_1&quot;\\n  input: &quot;Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.20301172493953412&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard for Visualization\n",
    "\n",
    "Tensorflow provides a very useful tool: Tensorboard. This is very helpful to visualize the training loss, accuray, filters,...\n",
    "\n",
    "Here is a good video about Tensorboard: https://www.youtube.com/watch?v=eBbEDRsCmv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def simple_model(X,y):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    \n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "    variable_summaries(Wconv1)\n",
    "    variable_summaries(W1)\n",
    "\n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1,[-1,5408])\n",
    "    y_out = tf.matmul(h1_flat,W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(2e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_with_tensorboard(session, predict, loss_value, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, tensorboard_writer=None):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    tf.summary.scalar(\"cost\", loss_value)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        batch_count = int(math.ceil(Xd.shape[0]/batch_size))\n",
    "        for i in range(batch_count):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            \n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            if training_now:\n",
    "                _, summary = session.run([training, summary_op],feed_dict=feed_dict)\n",
    "                # write log\n",
    "                tensorboard_writer.add_summary(summary, e * batch_count + i)\n",
    "            else:\n",
    "                summary = session.run(summary_op, feed_dict=feed_dict)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer\n",
      "Training\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=logs/train \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "# define SGD optimizer\n",
    "print('SGD optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter('logs/train', graph=tf.get_default_graph())\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model_with_tensorboard(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,\n",
    "                               tensorboard_writer=train_writer)\n",
    "\n",
    "# tensorboard --logdir=logs/train\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=logs/train \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "# NOTE: In Window, you may not able to run the Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "\n",
    "You are going to see [ADAM optimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) being used. Now, we will compare the training loss curves of a model with SGD and ADAM optimizers.\n",
    "\n",
    "You can try other optimizers, e.g., [SGD+Momentum](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer), [RMSprop](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer), [Adagrad](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer), [Adadelta](https://www.tensorflow.org/api_docs/python/tf/train/AdadeltaOptimizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 10.1 and accuracy of 0.12\n",
      "Iteration 100: with minibatch training loss = 2.43 and accuracy of 0.19\n",
      "Iteration 200: with minibatch training loss = 1.94 and accuracy of 0.17\n",
      "Iteration 300: with minibatch training loss = 1.62 and accuracy of 0.22\n",
      "Iteration 400: with minibatch training loss = 1.79 and accuracy of 0.12\n",
      "Iteration 500: with minibatch training loss = 1.53 and accuracy of 0.17\n",
      "Iteration 600: with minibatch training loss = 1.42 and accuracy of 0.22\n",
      "Iteration 700: with minibatch training loss = 1.43 and accuracy of 0.2\n",
      "Epoch 1, Overall loss = 1.86 and accuracy of 0.179\n",
      "Validation\n",
      "Epoch 1, Overall loss = 1.35 and accuracy of 0.21\n",
      "==========================================================\n",
      "\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 9.1 and accuracy of 0.11\n",
      "Iteration 100: with minibatch training loss = 1.71 and accuracy of 0.22\n",
      "Iteration 200: with minibatch training loss = 1.35 and accuracy of 0.27\n",
      "Iteration 300: with minibatch training loss = 1.41 and accuracy of 0.19\n",
      "Iteration 400: with minibatch training loss = 0.771 and accuracy of 0.42\n",
      "Iteration 500: with minibatch training loss = 0.731 and accuracy of 0.33\n",
      "Iteration 600: with minibatch training loss = 0.72 and accuracy of 0.36\n",
      "Iteration 700: with minibatch training loss = 0.775 and accuracy of 0.27\n",
      "Epoch 1, Overall loss = 1.18 and accuracy of 0.257\n",
      "Validation\n",
      "Epoch 1, Overall loss = 0.718 and accuracy of 0.324\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncfLGjYbjOI6TN240HMdxnLz5f92IT60WxoC+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e915f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = simple_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define SGD optimizer\n",
    "print('SGD optimizer')\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, sgd_losses = run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "\n",
    "print(\"==========================================================\\n\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses = run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "    \n",
    "plt.plot(sgd_losses, label='SGD')\n",
    "plt.plot(adam_losses, label='ADAM')\n",
    "# plt.plot(adam_losses_batchnorm, label='ADAM+BatchNorm')\n",
    "# plt.ylim( (0, 100) ) \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Epoch 1 Loss')\n",
    "plt.xlabel('minibatch number')\n",
    "plt.ylabel('minibatch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go Deeper\n",
    "\n",
    "In the previous exercises, you are required to implement different functions, e.g., affine, relu, conv2d, ... which serve as basic module to build a Deep Neuron Network. Similarly, we provide the basic modules for Tensorflow in `libs/tf_layers.py`.\n",
    "\n",
    "**NOTE:** In this exercise, you are welcome to change the block functions in `libs/tf_layers.py` to fit your needs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a deep network\n",
    "def deep_model(X, y, batchnorm=False, name=None):\n",
    "    output = Conv2D(X, 3, 7, 8, name=name+'_conv1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu1')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN1')\n",
    "    output = Conv2D(output, 8, 7, 8, name=name+'_conv2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu2')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN2')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool1')\n",
    "    output = Conv2D(output, 8, 7, 16, name=name+'_conv3')\n",
    "    output = tf.nn.relu(output, name=name+'_relu3')\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN3')\n",
    "    output = Conv2D(output, 16, 7, 16, name=name+'_conv4')\n",
    "    \n",
    "    # Here is another way of defining a name for a layer\n",
    "    with tf.variable_scope(name+'_relu4'):\n",
    "#         output = tf.nn.relu(output, name=name+'_relu4')\n",
    "        output = tf.nn.relu(output)\n",
    "    if batchnorm:\n",
    "        output = BatchNormalization(output, True, name=name+'_BN4')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool2')\n",
    "    output = tf.reshape(output, [-1, 16*8*8], name=name+'_flatten')\n",
    "    output = FullyConnected(output, 16*8*8, 100, name=name+'_fc1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu5')\n",
    "    output = FullyConnected(output, 100, 100, name=name+'_fc2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu6')\n",
    "    output = FullyConnected(output, 100, 10, name=name+'_fc3')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now see the benefit of using **batch normalization** layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of dask.optimize failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 385, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 324, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 267, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: cull() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of dask.delayed failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/dask/delayed.py\", line 13, in <module>\n",
      "    from .base import Base, is_dask_collection, dont_optimize\n",
      "ImportError: cannot import name 'is_dask_collection'\n",
      "]\n",
      "[autoreload of dask.array failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/dask/array/__init__.py\", line 4, in <module>\n",
      "    from .core import (Array, block, concatenate, stack, from_array, store,\n",
      "ImportError: cannot import name 'block'\n",
      "]\n",
      "[autoreload of dask.array.core failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/dask/array/core.py\", line 33, in <module>\n",
      "    from .numpy_compat import _make_sliced_dtype\n",
      "ImportError: cannot import name '_make_sliced_dtype'\n",
      "]\n",
      "[autoreload of dask.array.optimization failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 385, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 324, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 267, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: optimize() requires a code object with 3 free vars, not 0\n",
      "]\n",
      "[autoreload of dask.array.creation failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/dask/array/creation.py\", line 15, in <module>\n",
      "    from .core import (Array, asarray, normalize_chunks,\n",
      "ImportError: cannot import name 'broadcast_arrays'\n",
      "]\n",
      "[autoreload of dask.dataframe.methods failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 159, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'dask.dataframe' not in sys.modules\n",
      "]\n",
      "[autoreload of dask.dataframe.utils failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 159, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'dask.dataframe' not in sys.modules\n",
      "]\n",
      "[autoreload of dask.dataframe.accessor failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 159, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'dask.dataframe' not in sys.modules\n",
      "]\n",
      "[autoreload of dask.dataframe.categorical failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 159, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'dask.dataframe' not in sys.modules\n",
      "]\n",
      "[autoreload of dask.dataframe.hashing failed: Traceback (most recent call last):\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/nguyentrunghuan/anaconda3/lib/python3.6/importlib/__init__.py\", line 159, in reload\n",
      "    name=parent_name) from None\n",
      "ImportError: parent 'dask.dataframe' not in sys.modules\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 0.963 and accuracy of 0.16\n",
      "Iteration 100: with minibatch training loss = 0.289 and accuracy of 0.11\n",
      "Iteration 200: with minibatch training loss = 0.26 and accuracy of 0.17\n",
      "Iteration 300: with minibatch training loss = 0.246 and accuracy of 0.25\n",
      "Iteration 400: with minibatch training loss = 0.234 and accuracy of 0.23\n",
      "Iteration 500: with minibatch training loss = 0.231 and accuracy of 0.25\n",
      "Iteration 600: with minibatch training loss = 0.233 and accuracy of 0.28\n",
      "Iteration 700: with minibatch training loss = 0.225 and accuracy of 0.25\n",
      "Epoch 1, Overall loss = 0.258 and accuracy of 0.258\n",
      "Validation\n",
      "Epoch 1, Overall loss = 0.222 and accuracy of 0.321\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179e45438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out_deep2 = deep_model(X,y, True, name='deep2')\n",
    "# define our loss\n",
    "total_loss_deep2 = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out_deep2)\n",
    "mean_loss = tf.reduce_mean(total_loss_deep2)\n",
    "\n",
    "print(\"==========================================================\\n\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,1,64,100,train_step,False)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)\n",
    "    \n",
    "plt.plot(sgd_losses, label='SGD')\n",
    "plt.plot(adam_losses, label='ADAM')\n",
    "plt.plot(adam_losses_batchnorm, label='ADAM+BatchNorm')\n",
    "plt.ylim( (0, 100) ) \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Epoch 1 Loss')\n",
    "plt.xlabel('minibatch number')\n",
    "plt.ylabel('minibatch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More epochs\n",
    "Train the model with more epochs to see how good performance it can achieve.\n",
    "\n",
    "**NOTE:** If you run this on a CPU, it will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "ADAM optimizer\n",
      "Training\n",
      "Iteration 0: with minibatch training loss = 0.885 and accuracy of 0.062\n",
      "Iteration 100: with minibatch training loss = 0.285 and accuracy of 0.2\n",
      "Iteration 200: with minibatch training loss = 0.24 and accuracy of 0.27\n",
      "Iteration 300: with minibatch training loss = 0.233 and accuracy of 0.23\n",
      "Iteration 400: with minibatch training loss = 0.223 and accuracy of 0.25\n",
      "Iteration 500: with minibatch training loss = 0.223 and accuracy of 0.27\n",
      "Iteration 600: with minibatch training loss = 0.217 and accuracy of 0.28\n",
      "Iteration 700: with minibatch training loss = 0.215 and accuracy of 0.33\n",
      "Epoch 1, Overall loss = 0.245 and accuracy of 0.266\n",
      "Iteration 800: with minibatch training loss = 0.21 and accuracy of 0.33\n",
      "Iteration 900: with minibatch training loss = 0.215 and accuracy of 0.27\n",
      "Iteration 1000: with minibatch training loss = 0.205 and accuracy of 0.33\n",
      "Iteration 1100: with minibatch training loss = 0.223 and accuracy of 0.19\n",
      "Iteration 1200: with minibatch training loss = 0.211 and accuracy of 0.28\n",
      "Iteration 1300: with minibatch training loss = 0.203 and accuracy of 0.45\n",
      "Iteration 1400: with minibatch training loss = 0.209 and accuracy of 0.31\n",
      "Iteration 1500: with minibatch training loss = 0.207 and accuracy of 0.34\n",
      "Epoch 2, Overall loss = 0.455 and accuracy of 0.338\n",
      "Iteration 1600: with minibatch training loss = 0.217 and accuracy of 0.28\n",
      "Iteration 1700: with minibatch training loss = 0.205 and accuracy of 0.34\n",
      "Iteration 1800: with minibatch training loss = 0.207 and accuracy of 0.34\n",
      "Iteration 1900: with minibatch training loss = 0.208 and accuracy of 0.39\n",
      "Iteration 2000: with minibatch training loss = 0.218 and accuracy of 0.23\n",
      "Iteration 2100: with minibatch training loss = 0.185 and accuracy of 0.5\n",
      "Iteration 2200: with minibatch training loss = 0.201 and accuracy of 0.36\n",
      "Epoch 3, Overall loss = 0.66 and accuracy of 0.375\n",
      "Iteration 2300: with minibatch training loss = 0.212 and accuracy of 0.3\n",
      "Iteration 2400: with minibatch training loss = 0.199 and accuracy of 0.53\n",
      "Iteration 2500: with minibatch training loss = 0.216 and accuracy of 0.31\n",
      "Iteration 2600: with minibatch training loss = 0.183 and accuracy of 0.44\n",
      "Iteration 2700: with minibatch training loss = 0.207 and accuracy of 0.39\n",
      "Iteration 2800: with minibatch training loss = 0.196 and accuracy of 0.5\n",
      "Iteration 2900: with minibatch training loss = 0.2 and accuracy of 0.41\n",
      "Iteration 3000: with minibatch training loss = 0.182 and accuracy of 0.52\n",
      "Epoch 4, Overall loss = 0.86 and accuracy of 0.407\n",
      "Iteration 3100: with minibatch training loss = 0.191 and accuracy of 0.44\n",
      "Iteration 3200: with minibatch training loss = 0.2 and accuracy of 0.45\n",
      "Iteration 3300: with minibatch training loss = 0.203 and accuracy of 0.38\n",
      "Iteration 3400: with minibatch training loss = 0.201 and accuracy of 0.47\n",
      "Iteration 3500: with minibatch training loss = 0.189 and accuracy of 0.42\n",
      "Iteration 3600: with minibatch training loss = 0.174 and accuracy of 0.52\n",
      "Iteration 3700: with minibatch training loss = 0.2 and accuracy of 0.28\n",
      "Iteration 3800: with minibatch training loss = 0.19 and accuracy of 0.45\n",
      "Epoch 5, Overall loss = 1.05 and accuracy of 0.441\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ3kGbL0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cc8fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 0.187 and accuracy of 0.47\n"
     ]
    }
   ],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out_deep2 = deep_model(X,y, True, name='deep2')\n",
    "# define our loss\n",
    "total_loss_deep2 = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out_deep2)\n",
    "mean_loss = tf.reduce_mean(total_loss_deep2)\n",
    "\n",
    "print(\"==========================================================\")\n",
    "# define Adam optimizer\n",
    "print('ADAM optimizer')\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) # select optimizer and set learning rate\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_, adam_losses_batchnorm = run_model(sess,y_out_deep2,mean_loss,X_train,y_train,5,64,100,train_step,True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out_deep2,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a _GREAT_ model on CIFAR-10!\n",
    "\n",
    "### Things you should try:\n",
    "- **Filter size**: Above we used 7x7; bigger filters captures more information but smaller filters may be more computationally efficient.\n",
    "- **Number of filters**: Above we used 32 (or less) filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Use TensorFlow Scope**: Use TensorFlow scope and/or [tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers) to make it easier to write deeper networks. See [this tutorial](https://www.tensorflow.org/tutorials/layers) for how to use `tf.layers`. \n",
    "- **Use Learning Rate Decay**: [As the notes point out](http://cs231n.github.io/neural-networks-3/#anneal), decaying the learning rate might help the model converge. Feel free to decay every epoch, when loss doesn't change over an entire epoch, or any other heuristic you find appropriate. See the [Tensorflow documentation](https://www.tensorflow.org/versions/master/api_guides/python/train#Decaying_the_learning_rate) for learning rate decay.\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use [Dropout as in the TensorFlow MNIST tutorial](https://www.tensorflow.org/get_started/mnist/pros).\n",
    "\n",
    "**NOTE:**\n",
    "* In this exercise, you are welcome to change the block functions in `libs/tf_layers.py` to fit your needs the best.\n",
    "* Softmax cross-entropy loss: [tf.losses.softmax_cross_entropy](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/losses/softmax_cross_entropy)\n",
    "* SVM loss: [tf.losses.hinge_loss](https://www.tensorflow.org/api_docs/python/tf/losses/hinge_loss)\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should **see improvement within a few hundred iterations.**\n",
    "- Remember the **coarse-to-fine** approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should **use the validation set for hyperparameter search**, and we'll save the test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "\n",
    "\n",
    "### What we expect\n",
    "At the very least, you should be able to train a ConvNet that gets at **>= 60% accuracy on the validation set**. This is just a lower bound - if you are careful it should be possible to get accuracies much higher than that! Extra credit points will be awarded for particularly high-scoring models or unique approaches.\n",
    "\n",
    "You should use the space below to experiment and train your network. The final cell in this notebook should contain the training and validation set accuracies for your final trained network.\n",
    "\n",
    "Have fun and happy training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these; however they would be good things to try for extra credit.\n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum, RMSprop, and Adam; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "If you do decide to implement something extra, clearly describe it in the \"Extra Credit Description\" cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play with this cell\n",
    "# You can implement the model in a seperate python file.\n",
    "\n",
    "def my_model(X,y,is_training=True):\n",
    "    name = 'myModel'\n",
    "    output = Conv2D(X, 3, 7, 8, name=name+'_conv1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu1')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN1')\n",
    "    output = Conv2D(output, 8, 7, 8, name=name+'_conv2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu2')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN2')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool1')\n",
    "    output = Conv2D(output, 8, 7, 16, name=name+'_conv3')\n",
    "    output = tf.nn.relu(output, name=name+'_relu3')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN3')\n",
    "    output = Conv2D(output, 16, 7, 16, name=name+'_conv4')\n",
    "    output = tf.nn.relu(output, name=name+'_relu4')\n",
    "    output = BatchNormalization(output, True, name=name+'_BN4')\n",
    "    output = MaxPooling2D(output, name=name+'_maxpool2')\n",
    "    output = tf.reshape(output, [-1, 16*8*8], name=name+'_flatten')\n",
    "    output = FullyConnected(output, 16*8*8, 100, name=name+'_fc1')\n",
    "    output = tf.nn.relu(output, name=name+'_relu5')\n",
    "    output = FullyConnected(output, 100, 100, name=name+'_fc2')\n",
    "    output = tf.nn.relu(output, name=name+'_relu6')\n",
    "    output = FullyConnected(output, 100, 10, name=name+'_fc3')\n",
    "    return output\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = my_model(X,y,is_training)\n",
    "my_total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "my_mean_loss = tf.reduce_mean(my_total_loss)\n",
    "my_optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "# extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = my_optimizer.minimize(my_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play with this cell\n",
    "# This default code creates a session\n",
    "# and trains your model for 10 epochs\n",
    "# then prints the validation set accuracy\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    _,_,outout = run_model(sess,y_out,mean_loss,X_train,y_train,10,64,100,train_step,True)\n",
    "    print('Validation')\n",
    "    run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model here, and make sure \n",
    "# the output of this cell is the accuracy\n",
    "# of your best model on the training and val sets\n",
    "# We're looking for >= 60% accuracy on Validation\n",
    "print('Training')\n",
    "run_model(sess,y_out,mean_loss,X_train,y_train,1,64)\n",
    "print('Validation')\n",
    "run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set - DO THIS ONLY ONCE\n",
    "Now that we've gotten a result that we're happy with, we test our final model on the test set. This would be the score we would achieve on a competition. Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test')\n",
    "run_model(sess,y_out,mean_loss,X_test,y_test,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit Description\n",
    "Briefly describe what you did here.\n",
    "\n",
    "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tell us here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
